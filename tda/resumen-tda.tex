\documentclass{article}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{fancyhdr}

\usepackage{mathtools}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\pagestyle{fancy}
\fancyhf{}

\rhead{\leftmark}
\fancyfoot[LE,RO]{\thepage}


\renewcommand{\baselinestretch}{1.2}
\setlength{\parskip}{1em}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}


\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\begin{document}

\newpage{}
\tableofcontents
\newpage{}

\newpage
\section{Stable Maching problema}

\subsection{Algoritmo Gale-Shapley}
Este algoritmo al terminar de ejecutarse se encuentra un matching prefecto si:
\begin{itemize}
    \item Si existen \(n\) solicitantes con diferentes preferencias.
    \item Si existen \(n\) requeridos con diferentes preferencias.
\end{itemize}
Eligiendo las estructuras correctamente se puede plantear en \(O(n)\).

\begin{lstlisting}[language=Python, caption=Algoritmo de Gale-Shapley]
    Inicialmente M=Vacio
    
    Mientras existe un solicitante sin pareja que no aun se haya postulado a todas las parejas
    
        Sea s un solicitante sin pareja
        Sea r el requerido de su mayor preferencia al que no le
                    solicito previamente
            
        if r esta desocupado
            M = M U (s,r)
            s esta ocupado
        else
            Sea s' tal que (s', r) pertenece a M

            si r prefiere a s sobres s'
                M = M - {(s', r)} U (s,r)
                s esta ocupado
                s' esta libre
    Retornar M
    
\end{lstlisting}    

\newpage
\subsection{Alternativas}
\subsubsection{Diferentes cantidades de oferentes que requeridos}

Dado n oferentes y m requeridos, con \(m <> n\), no se puede encontrar un matching stable. 

Entonces, tenemos que redefinir el concepto de estable. Una pareja (s,r) es \textbf{estable} si:
\begin{itemize}
    \item No existe requerido r' sin pareja al que s prefiera a su actual pareja.
    \item No existe un requerido r' en pareja, tal que s y r' se prefieran sobre sus respectivas parejas.
    \item No existe solicitante s' sin pareja al que r prefiera a su actual pareja.
    \item No existe un solicitante s' en pareja tal que r y s' se prefieran sobre sus respectivas parejas.
\end{itemize}    


Por lo tanto un matching es estable si:
\begin{itemize}
    \item No tienen parejas inestables bajo la condicion anterior.
    \item Que no queden requeridos y solicitantes sin pareja.
\end{itemize}

Soluciones para ajustar al modelo de Gale-Shapley:
\begin{enumerate}
    \item Inventar \(|n-m|\) elementos ficticios
    \begin{itemize}
        \item Los elementos ficticios se pondran en las listas de preferencias con menos elementos.
        \item Estos elementos ficticios se agregan al final y deben ser los menos preferidos.
        \item Luego ejecutar Gale-Shapley
        \item Por ultimo, eliminar las parejas con elementos ficticios. Estos seran los requeridos que quedan sin pareja.
    \end{itemize}
    \item Adecuar el Algoritmo
    \begin{itemize}
        \item Si hay mas \textbf{solicitantes} que requeridos, quitar de la \textit{lista de solicitantes} sin parejas a aquellos que agotaron sus propuestas.
        \item Si hay mas \textbf{requeridos} que solicitantes, quitar de la \textit{lista de parejas} a aquellas donde el requerido quedo sin pareja.
    \end{itemize}
\end{enumerate}

\newpage
\subsubsection{Preferencias incompletas}
Las listas de preferencias de los oferentes y los requeridos son un subset de las contrapartes.

Son parejas \textbf{aceptables} de un elemento a aquellas contrapartes que figuran en su lista de preferencias.

Una pareja (s,r) es \textbf{estable} si:
\begin{itemize}
    \item Son \textit{aceptables} entre ellos.
    \item No existe requerido \textit{aceptable} r' sin pareja al que s prefiera a su actual pareja.
    \item No existe un requerido \textit{aceptable} r' en pareja, tal que s y r' se prefieran sobre sus respectivas parejas.
    \item No existe solicitante \textit{aceptable} s' sin pareja al que r prefiera a su actual pareja.
    \item No existe un solicitante \textit{aceptable} s' en pareja tal que r y s' se prefieran sobre sus respectivas parejas.
\end{itemize}

\begin{quote}
    \textbf{Un matching es estable si no tiene parejas inestables bajo la condicion anterios.}
\end{quote}

\begin{lstlisting}[language=Python, caption=Algoritmo para parejas incompletas]
Inicialmente M=Vacio

#Iterea mientras no haya acotado su sublista de preferencias
Mientras existe un solicitante sin pareja
                'que no aun se haya postulado a todas las parejas' 

    Sea s un solicitante sin pareja
    Sea r el requerido de su mayor preferencia al que no le
                solicito previamente
    
    # se condiera si es aceptable
    if r considera 'aceptable' a s

        if r esta desocupado
            M = M U (s,r)
            s esta ocupado
        else
            Sea s' tal que (s', r) pertenece a M
            si r prefiere a s sobres s'
                M = M - {(s', r)} U (s,r)
                s esta ocupado
                s' esta libre

# Retornar solo parejas aceptables
Retornar M

\end{lstlisting}    


\subsubsection{Preferencias con empates}


\textbf{INDIFERENCIA Y PREFERENCIA ESTRICTA}

\begin{enumerate}
    \item X es \textbf{indiferente} a "y" y a "z" si en su lista de preferencias estan el la misma posicion.
    \item X es \textbf{prefefiere estrictamente} a "y" sobre "z" si en su lista de preferencias no le son indiferentes y 
          "y" se encuentra antes que "z" en la misma.
\end{enumerate}

\noindent
\textbf{ESTABILIDAD DEBIL}
\newline Una pareja (s,r) es debilmente estable si no existe una pareja (s' y r') talque:
\begin{itemize}
    \item s prefiere estrictamente a r' sobre r \textit{(pareja actual de s)}
    \item r' prefiere estrictamente a s sobre s' \textit{(pareja actual de r')}
\end{itemize}



\begin{lstlisting}[language=Python, caption=Algoritmo para parejas incompletas]
    Inicialmente M=Vacio
    
    #Iterea mientras no haya acotado su sublista de preferencias
    Mientras existe un solicitante sin pareja
                    'que no aun se haya postulado a todas las parejas' 
    
        Sea s un solicitante sin pareja
        Sea r el requerido de su mayor preferencia al que no le
                    solicito previamente
            
        if r esta desocupado
            M = M U (s,r)
            s esta ocupado
        else
            Sea s' tal que (s', r) pertenece a M

            # prefiere estrictamente
            si r prefiere estrictamente a s sobres s'
                M = M - {(s', r)} U (s,r)
                s esta ocupado
                s' esta libre
    
    Retornar M
    
\end{lstlisting}    
\begin{quote}
    En caso de que sea empate, se mantendra con su pareja actual.
\end{quote}

\noindent
\textbf{ESTABILIDAD FUERTE}
\newline Una pareja (s,r) es debilmente estable si no existe una pareja (s' y r') talque:
\begin{itemize}
    \item s prefiere estrictamente o le es indiferente a r' sobre r \textit{(pareja actual de s)}
    \item r' prefiere estrictamente o le es indiferente a s sobre s' \textit{(pareja actual de r')}
\end{itemize}
Puede no existir un matching perfecto.

\begin{lstlisting}[language=Python, caption=Algoritmo para parejas super estables]
    Inicialmente M=Vacio
    
    Mientras existe un solicitante sin pareja y no exista solicitante que agoto sus parejas
    
        Sea s un solicitante sin pareja
        Sea r el requerido de su mayor preferencia al que pueda proponer
        Por cada sucesor s' a s en la lista de preferencias de r
            if (s',r) pertenece a M
                M = M - {(s',r)}
                s' esta libre
            quitar s' de la lista de preferencias de r
            quitar r de la lista de preferncias de s'

        Por cada requerido r' que tiene multiples parejas
            Por cada pareja s' en pareja con r' 
                M = M - {(s',r')}
                quitar s' de la lista de preferencias de r'
                quitar r' de la lista de preferencias de s'

    if estan todos en pareja
        Retornar M
    else
        No existe ningun matching super estable
\end{lstlisting}    
\begin{quote}
    En caso de que sea empate, se mantendra con su pareja actual.
\end{quote}

\newpage
\subsubsection{Agrupacion de 1 a muchos}
El solicitante puede tener varios cupos por lo tanto:
\begin{itemize}
    \item Exiten \(m\) requeridos, donde un requerido puede estar unicamente con 1 pareja.
    \item Exiten \(n\) solicitantes, donde cada solicitante puede tener \(c\) cupos para armar parejas.
\end{itemize}

Existe un matching estable si la cantidad de requeridos es igual a la cantidad de solicitantes por la cantidad de cupos.

\begin{equation} \label{eu_eqn}
    m=n*c
\end{equation}

No cambia la definici√≥n de Gale Shampey para \textbf{matching estable}

\begin{lstlisting}[language=Python, caption=Algoritmo de solicitantes con cupos]
    Inicialmente M=Vacio
    
    Mientras exista un solicitante con cupo disponible
    
        Sea s un solicitante sin pareja
        Sea r el requerido de su mayor preferencia al que no le
                    solicito previamente
            
        if r esta desocupado
            M = M U (s,r)
            s decremente su disponibilidad de parejas
        else
            Sea s' tal que (s', r) pertenece a M

            si r prefiere a s sobres s'
                M = M - {(s', r)} U (s,r)
                s decremente su disponibilidad de parejas
                s' incrementa su disponibilidad de parejas
    Retornar M
    
\end{lstlisting}    
\begin{quote}
    \textbf{La complejidad algoritmica no se modifica porque solo se agrega un contador.}
\end{quote}

\newpage
\subsubsection{Agrupacion de muchos a 1}
El requerido puede tener varios cupos por lo tanto:
\begin{itemize}
    \item Exiten \(m\) requeridos, donde cada solicitante puede tener \(z\) cupos para armar parejas.
    \item Exiten \(n\) solicitantes, donde un requerido puede estar unicamente con 1 pareja.
\end{itemize}

Existe un matching estable si la cantidad de solicitantes es igual a la cantidad de requeridos por la cantidad de cupos.

\begin{equation} \label{eu_eqn}
    n=m*z
\end{equation}

No cambia la definici√≥n de Gale Shampey para \textbf{matching estable}

\begin{lstlisting}[language=Python, caption=Algoritmo de requeridos con cupos]
    Inicialmente M=Vacio
    
    Mientras exista un solicitante con cupo disponible
    
        Sea s un solicitante sin pareja
        Sea r el requerido de su mayor preferencia al que no le
                    solicito previamente
            
        if r tiene cupo 
            M = M U (s,r)
            s esta ocupado
            r decrementa su disponibilidad de parejas
        else
            Sea s' tal que (s', r) pertenece a M y 
                    s' es el menos preferidos de las parejas r

            si r prefiere a s sobres s'
                M = M - {(s', r)} U (s,r)
                s esta ocupado
                s' esta libre
    Retornar M
    
\end{lstlisting}    
\begin{quote}
    \textbf{La complejidad algoritmica si se modifica.}
\end{quote}
Para conocer el solicitante de menor preferencia podemos utilizar un heap de minimos. Como el cupo es de z, la complejidad algoritmica para actualizar el heap es \(log (z)\).

\newpage
\subsubsection{Agrupacion de y a x}
\begin{itemize}
    \item Exiten \(n\) solicitantes, donde cada solicitante puede tener \(c\) cupos para armar parejas.
    \item Exiten \(m\) requeridos, donde cada requerido puede tener \(z\) cupos para armar parejas.
\end{itemize}


Existe un matching estable si:

\begin{equation} \label{eu_eqn}
    n*c=m*z
\end{equation}


No cambia la definici√≥n de Gale Shampey para \textbf{matching estable}
\newline
Para implementar se requieren las siguientes estructuras:
\begin{itemize}
    \item Un heap de minimos para los requeridos.
    \item Un contador de cupos para los solicitantes.
\end{itemize}

\begin{quote}
    \textbf{La complejidad algoritmica es igual a la de los requeridos con cupos}
\end{quote}

\newpage
\subsubsection{Conjuntos no bipartios - Stable Roommate Problem}
Pendiente

\newpage
\section{Analisis amortizado}

\subsubsection{Metodo de agregacion}
\subsubsection{Metodo del banquero}
\subsubsection{Metodo del potencial}

\newpage
\subsubsection{Heap binomial y fibonacci}
Revisar capitulo 19 del Corven.
\newline
Para el \textbf{heap binomial} se utilizan bosques de arboles binarios. Existe un proceso donde se van ordenando los arboles.

Al insertar, se parece al ejemplo de contador binario y la amortizacion es O(1)
\newline
Decrementar en un log binomial, es log(n) porque no es posible amortizar
\newline 
Eliminar el minimo, es el el peor caso es log(n)

Para el \textbf{heap fibonacci} ...

\section{Algoritmos Greedy}

Utiliza heurisica de seleccion para encontrar una soluci√≥n global optima despues de muchos pasos.

\subsection{Mochila fraccionaria}

Dado un contener de capacidad W, y un conjunto de elementos n fraccionables de valor \(v_i\) y peso \(w_i\)

El objetivo es seleccionar un subconjunto de elemento o fracciones de ellos de modo de maximizar el valor almacenado y sin superar la capacidad de la mochila.

La complejidad es \(O(nlog(n))\)

\newpage
\subsection{Cambio de moneda}

Es una soluci√≥n es conocido como soluci√≥n de cajero. Contamos con un conjunto de diferentes monedas de diferentes denominaci√≥n sin restricci√≥n de cantidad.

\[
    \$=(C_1,C_2,C_3,\cdots,C_n)  
\]

El objetivo es entregar la menor cantidad posible de monedas como cambio.

Tiene una complejidad de \(O(n)\).

El sistema \(\$\) se conoce como \textbf{canonico} a aquel en el que para todo x, \(greedy(\$,x)=optimo(\$,x)\).

Para saber si una base es canonica:
\begin{enumerate}
    \item Basta con buscar un contraejemplo. Estaria entre la 3ra denomininacion y la suma de las ultimas dos doniminaciones.
    \item Utilizar un algoritmo Polinimico para determinar si es un sistema canonico.
\end{enumerate}

Si el problema no es greddy, se puede construir un algoritmo utilizando programaci√≥n dinamica.


\newpage
\subsection{Interval Scheduling: Algoritmo de Greedy Stay Ahead}

Tenemos un conjunto de requests \(\{1,2,..,n\}\); el request \(i^{th}\) corresponde a un intervalo de tiempo que comienza al instante \(s(i)\) y finaliza al instante \(f(i)\).
Diremos que un subconjunto de requests es compatible si no hay dos de ellos que al mismo tiempo se superponen, y nuestro objetivo es aceptar un subconjunto compatible tan grande como sea posible. El conjunto compatible con mayor tama√±o sera el \textbf{√≥ptimo}.

La idea b√°sica en un algoritmo greedy para interval scheduling es usar una simple regla para seleccionar el primer request \(i_1\). Una vez que el request \(i_1\) aceptado, rechazamos todos los request que no son compatibles con \(i_1\). Luego seleccionamos el siguiente request \(i_2\), y volvemos a rechazar todos lo request que no son compatibles con \(i_2\). 
Continuamos de esta manera hasta que nos quedemos sin requests. El desafio en dise√±ar un buen algoritmo greedy esta en decidir que regla usar para la selecci√≥n.

Pueden probar con varias reglas, pero las mas optimo es la siguiente idea: Aceptaremos el request que termina primero, o sea el request para el cual tiene el menor \(f(i)\) posible. 
Asi nos aseguramos que nuestros recursos se liberen tan pronto como sea posible mientras satisfacemos un request. De esta manera podemos maximizar el tiempo restante para satisfacer otro request.

Para escribir el pseudo c√≥digo, utilizaremos \(R\) para denotar al conjunto de request que a√∫n no estan aceptados ni rechazados, y usaremos \(A\) para denotar al conjunto de los request aceptados.

\begin{lstlisting}[language=Python, caption=Algoritmo de greedy para Interval Scheduling]
Inicialmente R contiene todos los requests, y A es un conjunto vacio.

Mientras R no esta vacio

    Seleccionar un request i de R que tenga el instante de finalizacion mas chico.
    Agregar el registro i a A
    Eliminar todos los request de R que no sean compatibles con el request i    

Fin mientras

Retornar el conjunto A como el conjunto de los request aceptados.

\end{lstlisting}    


\begin{figure}[h!]
    \includegraphics[width=\linewidth]{imagenes/intervalos-compatibles.png}
\end{figure}

\begin{quote}
    De forma inmediata podemos decir que el conjunto retornado tiene request compatibles.
\end{quote}

Lo que necesitamos es demostrar que la soluci√≥n es optima. Definimos a \(O\), un conjunto de intervalos optimos. 
Luego, vamos a mostrar que \(|A| = |O|\), o sea que el conjunto \(A\) tiene la misma cantidad de intervalos que \(O\), y por lo tanto, \(A\) tambien es una soluci√≥n optima.

Para la prueba introduciremos la siguiente notaci√≥n:
\begin{itemize}
    \item Dado \(\{i_1,...,i_k\}\) el conjunto de request en \(A\) en orden que fueron agregados a \(A\). Notar que \(|A|=k\).
    \item Dado \(\{j_1,...,j_m\}\) el conjunto de request en \(O\) ordenos de izquierda a derecha. Notar que \(|O|=m\).
\end{itemize}
El objetivo es probar que \(k=m\).

La manera en que el algoritmo de greedy se mantenga adelante(\textbf{stays ahead}) es que cada uno de sus intervalos finalice al menos tan pronto como lo haga el correspondiente intervalo en el conjunto \(O\).

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{imagenes/demo-greedy-intervalos.png}
\end{figure}

\begin{quote}
    \textbf{(3.1) Para todos los indices \(r<k\) tenemos que \(f(i_r) \leq f(j_r)\)}
\end{quote}

\textbf{Demostraci√≥n:}  Probaremos la sentencia anterior mediante el m√©todo inductivo. Para \(r=1\) la sentencia anterior es cierta, el algoritmo empieza seleccionando el request \(i_1\) con el menor tiempo de finalizaci√≥n.

Para el caso inductivo, o sea \(r>1\) asumiremos como nuestra hipotesis inductiva que la sentencia es verdadera para \(r-1\), y queremos probar que es tambien es lo es para \(r\). La hipotesis inductiva nos dice que asumamos verdadero que \(f(i_{r-1}) \leq f(j_{r-1})\). Queremos demostrar que \(f(i_{r}) \leq f(j_{r})\).

Dado que \(O\) consiste en intervalos compatibles, sabemos que \(f(j_{r-1}) \leq s(j_r)\). Combinando esto √∫ltimo con la hipotesis inductiva \(f(i_{r-1}) \leq f(j_{r-1})\), obtenemos \(f(i_{r-1}) \leq s(j_{r})\). Asi el intervalo \(j_r\) esta en conjunto \(R\) de los intervalos disponibles al mismo tiempo cuando el algoritmo de greedy selecciona \(i_r\).
El algoritmo de greedy selecciona el intervalo con el \textit{tiempo final mas chico} (\(i_{r}\)); y dado que intervalo \(j_{r}\) es uno de estos intervalos, tenemos que \(f(i_r) \leq f(j_r)\), completando asi el paso inductivo.

De esta forma demostramos que nuestro algoritmo se mantiene adelante del conjunto optimo \(O\). Ahora veremos porque esto implica optimalidad del conjunto \(A\) de algoritmo de greedy.

\begin{quote}
    \textbf{El algoritmo de greedy retorna un conjunto \(A\) √≥ptimo.}
\end{quote}

\textbf{Demostraci√≥n:} Para demostrarlo utilizaremos la contradicci√≥n. Si \(A\) no es optimo, entonces el conjunto \(O\) debe tener mas requests, o sea que tenemos \(m>k\) y aplicando 3.1, cuando r=k, 
obtenemos que \(f(i_k) \leq f(j_k)\). Dado que \(m>k\), existe un request \(j_{k+1}\) en \(O\). Este request empieza despues que el request \(j_k\) termina y por consiguiente despues de que el request \(i_k\) termine.
Entonces, despues de eliminar todos los requests que no son compatibles con los request \(i_1,...,i_k\), el conjunto de posibles requests R a√∫n contiene el requests \(j_{k+1}\). 
Pero el algoritmo de greedy se detiene con el request \(i_k\) y este supuestamente se detiene porque \(R\) esta vacio, lo cual es una contradicci√≥n. 


\newpage
\subsection{Seam Carving - TODO}
Es un algoritmo para adecuar imagenes. Analiza imagenes recortando pixeles de menor importancia. Retira tantas vetas como sea necesario para llegar a un tama√±o optimo.


\subsection{Caminimos Minimos - TODO}

Dado dos nodos, uno inicial \(s\) y otro final \(t\) el algoritmo encuentra el camino minimo que los une, tambien entre \(s\) y el resto de los nodos.

\subsection{Compresi√≥n de datos - TODO}

El algoritmo de greedy arma un arbol de "hufman" para armar un arbol optimo de prefijos.

\section{Divisi√≥n y conquista}

\subsection{Encontrar un par de puntos mas cercanos}

\textbf{Problema}: Dado \(n\) puntos en el plano, encontrar el par de puntos mas cercanos.

\textbf{Dise√±o}: Definimos el conjunto de puntos \(P=\{p_1,..., p_n\}\) donde \(p_i\) tiene las
coordenadas \(x_i, y_i\); y por cada dos puntos \(p_i, p_j \in P\) usamos \(d(p_i,p_j)\) como 
la distancia euclideana entre ellos. El objetivo es buscar un par de puntos \(p_i, p_j\) que minimice
la distancia \(d(p_i,p_j)\).

Se asume que no hay dos puntos que tengan las misma coordenadas. En dos dimensiones
ordenaremos los puntos en base a los ejes \(x\) e \(y\) y utilizaremos division y conquista
para encontrar los puntos mas cercanes en la \textit{mitad de derecha} de P y los 
puntos mas cercanes en la \textit{mitad de izquierda} de P.

Por ultimo, las distancias no consideradas en las llamadas recursivas son las que estan 
cercanos a la parte izquierda y derecha de la divisi√≥n de P.




\newpage
\section{Programaci√≥n dinamica}

\subsection{Cambio de monedas}

Contamos con un conjunto de monedas de diferente denominaci√≥n sin restricci√≥n de cantidad. 
Representamos de esta manera \(\$=(c_1,c_2,....,c_n)\) y tenemos un importe \(x\) a dar. 
Concluimos que no existe un algoritmo satisfactorio de greedy para resolver este problema.

Si buscamos la soluci√≥n por \textbf{fuerza bruta}, se puede armar un arbol de decisi√≥n. 
Por cada moneda posible, se genera un subproblema. 

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{imagenes/dinamico-arbol-moneda.png}
\end{figure}

Entonces el camino a la hoja con menor profundidad es la menor cantidad de monedas a dar. Esto hace que la complejidad sea \(O(x^n)\).

Analizando el problema anteriores se pueden obtener algunas mejoras. 
Parte de los caminos del arbol son iguales. 
Hay distintas ramas con nodos que tienen el mismo resto, 
y por lo tanto se puede calcular solo una vez. 
Este caso de resto igual en varios nodos, lo llamaremos subproblemas.

\begin{figure}[h!]
    \includegraphics[scale=0.5]{imagenes/dinamico-moneda-subproblema.png}
\end{figure}

\newpage
\textbf{Subproblema}: Calcular el √≥ptimo(OPT) del cambio \(x\) debe usar el m√≠nimo entre los subproblemas \(X - C_j\) para \(j=1...n\).

Cada vez que paso por un subproblema se incremente en \(1\) para contar la cantidad de monedas a dar. 
Que seria: \(1+min\{subproblemas\}\).

Para la soluci√≥n \textbf{recurrente}, podemos plantear:

    \[
        \left\{ \begin{array}{lcc}
            OPT(x) = 0 &   si  & x = 0 \\
            \\ OPT(x) = 1+min\{OPT(x-C_i)\} &  si & x > 0 \\
            \end{array}
        \right.
    \]

El resultado con el minimo cambio sera OPT(x) y para poder calcularlo, 
necesito calcular los \(x-1\) √≥ptimos anterios. 
Para evitar el recalculo, si calculo el optimo de algun resto, 
lo almaceno para no volver a calcularlo de nuevo.
Ademas en cada subproblema debo analizar \(n\) comparaciones, lo cual impacta en la complejidad.

\newpage
\noindent
\underline{SOLUCI√ìN ITERATIVA}
\begin{lstlisting}[language=Python, caption=Soluci√≥n iterativa]

OPT[0] = 0
Desde i=1 a X
    minimo = +infinito
    Desde j=1 a n
        resto = i - C[j]
        si resto > 0 y minimo > OPT[resto]
            minimo = OPT[resto]
    
    OPT[i] = 1 + minimo

Retornar OPT[X]
\end{lstlisting}

La complejidad es \(O(X*n)\) porque no solo depende de los diferentes tipos de monedas, tambien
depende del parametro de entrada \(X\). Se dice que es un algoritmo pseudo polinomial.

\noindent
\underline{RECONSTRUIR LAS ELECCIONES}

\begin{lstlisting}[language=Python, caption=Soluci√≥n iterativa con reconstrucci√≥n]

OPT[0] = 0
elegida[0] = 0
Desde i=1 a X
    minimo = +infinito
    elegida[i] = 0
    Desde j=1 a n
        resto = i - C[j]
        si resto > 0 y minimo > OPT[resto]
            elegida[i] = j
            minimo = OPT[resto]
    
    OPT[i] = 1 + minimo

resto = x
Mientras resto > 0
    Imprimir C[elegida[resto]]
    resto = resto - C[elegida[resto]]

Imprimir OPT[x]

\end{lstlisting}

\newpage
\subsection{Problema de la Publicidad en la carretera}

Sea una carretera de longitud \(M\) km, un conjunto de \(n\) carteles publicitarios en el 
intevalo \([0,M]\), cada cartel \(i\) tiene una posici√≥n \(x_i\) y un valor de ganancia \(r_i\).
Entonces queremos seleccionar carteles para maximizar la ganancia. Como restriccci√≥n ning√∫n cartel
puede estar a menos de 5 km de otro.

\begin{figure}[h!]
    \includegraphics[scale=0.4]{imagenes/dinamico-ejemplo-ruta.png}
\end{figure}

Podemos armar un arbol de decisi√≥n utilizando una funcion de \textit{anteriores(i)}. La funci√≥n anterior
nos dice cual es el cartel anterior al \(i\) que cumple con la restriccci√≥n.

\begin{figure}[h!]
    \includegraphics[scale=0.4]{imagenes/dinamico-ruta-arbol.png}
\end{figure}


Para la soluci√≥n \textbf{recurrente}, podemos plantear:

\[
    \left\{ \begin{array}{lcc}
        OPT(i) = 0 &   si  & i = 0 \\
        \\ OPT(i) = max\{r_i + OPT(anterior(i)), OPT(i-1) \} &  si & i > 0 \\
        \end{array}
    \right.
\]

El resultado con la m√°xima ganancia sera: \(OPT(n)\). 

\noindent
\textbf{\underline{SOLUCI√ìN ITERATIVA}}

\begin{lstlisting}[language=Python, caption=Soluci√≥n iterativa]

OPT[0] = 0
OPT[1] = r[1]

Desde i=2 a n

    estaCartel = r[i] + OPT[anterior(i)]
    noEstaCartel = OPT[i-1]

    OPT[i] = max (estaCartel, noEstaCartel)

Retornar OPT[n]
\end{lstlisting}


\noindent
\textbf{\underline{SOLUCI√ìN ITERATIVA - CARTELES SELECCIONADOS}}

\begin{lstlisting}[language=Python, caption=Soluci√≥n iterativa con reconstrucci√≥n]

OPT[0] = 0
OPT[1] = r[1]
elegidos[0] = false
elegidos[1] = true

Desde i=2 a n

    estaCartel = r[i] + OPT[anterior(i)]
    noEstaCartel = OPT[i-1]

    Si estaCartel>noEstaCartel 
        elegido[i] = true
    sino
        elegido[i] = false

    OPT[i] = max (estaCartel, noEstaCartel)

Retornar OPT[n]
\end{lstlisting}


La complejidad temportal es \(O(n)\) ya que solo hago sumas y comparaciones. La complejidad espacial
es \(O(n)\) porque se almacenan los \(n\) √≥ptimos en un array.

\noindent
\textbf{\underline{SOLUCI√ìN ITERATIVA - RECONSTRUIR}}

\begin{lstlisting}[language=Python, caption=Soluci√≥n iterativa]

i = n

Mientras i>0
    si elegido[i]
        Imprimir i
        i = anterior[i]
    sino 
        i = i-1

Retornar OPT[n]
\end{lstlisting}


La complejidad temportal es \(O(n)\). La complejidad espacial es \(O(n)\).



\noindent
\textbf{\underline{CALCULO anterior de i}}


Se hace un apareo entre las posiciones del cartel \(x\) y el limite del mismo. 
El objetivo es armar un array de anteriores.

\begin{lstlisting}[language=Python, caption=Soluci√≥n iterativa]

i=n
j=n-1

Mientras i>1
    Si limite(n) >= posicion(j)
        anterior[i] = j
        i=i-1
    sino
        j=j-1

\end{lstlisting}


\newpage
\subsection{Programaci√≥n de intervalos ponderados}


\newpage
\subsection{Problema de Knapsack (mochila) }

\newpage
\subsection{Problema de Subset Sum }

Sea un conjunto de \(n\) elementos \(E=\{e_1, e_2, ..., e_n \}\) donde cada elemento \(e_i\) 
cuenta con un peso asociado \(w_i\).

Queremos seleccionar un subset de elementos de E con el mayor peso posible que no supere un 
valor \(W\) de peso m√°ximo.

Para plantear una soluci√≥n por \textbf{fuerza bruta}, un elemento puede estar o no. O sea que si
tengo \(n\) elementos pueden existir \(2^n\) combinaciones. Entonces la complejidad total esta acotado
por \(O(2^n)\).

Definimos \(OPT(i, w)\) como el valor optimo de la soluci√≥n usando un subconjunto de items \(\{1,..,i\}\)
con un m√°ximo de peso permitido \(w\)

\begin{itemize}
    \item Si \(n \notin O\), entonces \(OPT(n,W) = OPT(n-1, W)\), ignorando el elemento n
    \item Si \(n \in O\), entonces \(OPT(n,W) = w_n + OPT(n-1, W-w_n)\), desde ahora buscaremos
            utilizar lo que queda de capacidad \(W-w_n\) para hallar el optimo en los items \(\{1,2,..,n-1\}\).

\end{itemize}


\begin{lstlisting}[language=Python, caption=Algoritmo de requeridos con cupos]
Subset-Sum(n, W)
    Array M[0...n,0...W]
    Inicializar M[0,w]=0 para cada w=0,1,...,W
    Para cada i=1,2,...,n
        Para cada w=0,...,W
            Usar la reccurrencia para computar M[i,W]
        Fin para
    Fin para
    Retornar M[n, W]
\end{lstlisting}





\newpage
\subsection{Bellman Ford}

Se extiendo el problema de hallar caminos minimos utilizando \textbf{aristas ponderas negativas}. 
Se puede hayar un camino global que pase por aristas ponderadas negativamente y que sea el optimo, 
en vez de utilizar un algoritmo de greedy de \textit{Dijkstra} que para este caso no seria √≥ptimo.

Una soluci√≥n por \textbf{fuerza bruta} seria, calcular para un grafo poderado \textbf{sin ciclos negativos}:

\begin{itemize}
    \item Todos los costos de los caminos posibles de \(s\) a \(t\) de longitud 1.
    \item Todos los costos de los caminos posibles de \(s\) a \(t\) de longitud 2.
    \item ...
    \item Todos los costos de los caminos posibles de \(s\) a \(t\) de longitud n-1.
\end{itemize}

\textbf{El camino m√≠nimo tendra longitud n-1 como m√°ximo} sin ciclos negativos.

El algoritmo de \textbf{Bellman-Ford} halla el camino m√≠nimo con aristas negativos utilizando programaci√≥n din√°mica.

\underline{AN√ÅLISIS}

Para llegar desde "s" a un nodo \(n_i\) puede haber utilizado diferntes caminino y longitudes.
Lo puede hacer a trav√©s de sus nodos predecesores \(pre[n_i]\).

Para poder llegar a \(n_i\) en \(j\) pasos, tengo que haber llegado a sus predeceroes en \(j-1\) pasos. 
Asi sucesivamente hasta "s" se puede ir resolviendo \textit{sub casos}.

Definimos \(minPath(n,j)\) al camino m√≠nimo hasta el nodo \(n_i\) con longitud m√°xima \(j\).

\underline{SOLUCI√ìN RECURRENTE}

\begin{align*}
minPath('s', j) &= 0 \\
minPath(n_i, 0) &= +\infty & n_i \neq s \\
minPath(n_i, j) &=min\left\{\begin{array}{ll}
                minPath(n_i, j-1)              \\
                min \{minPath(n_x, j-1) + w(n_x, n_i)\}          
        \end{array}\right. & n_x \in pred(n_i)
\end{align*}

\begin{itemize}
    \item El camino m√≠nimo a 's' para cualquier longitud es siempre 0.
    \item El camino m√≠nimo a \(n_i\) al comienzo es infinito.
    \item TODO
\end{itemize}

\underline{SOLUCI√ìN ITERATIVA}

Definimos a \(OPT[l][v]\) como el camino m√≠nimo de "s" al nodo \(n\) con longitud\(l\)

El nodo "s" se encuentra en v=0
El nodo "t" se encuentra en v=n

\begin{lstlisting}[language=Python, caption=Algoritmo de requeridos con cupos]
    Desde l=0 a n-1
        OPT[l][0] = 0
    Desde v=0 a n-1
        OPT[0][v] = +infinito


    Desde l=1 a n-1   // max longitud del camino
        Desde v=1 a n // nodo
            OPT[l][v] = OPT[l-1][v]
            Por cada p predecesor de v
                si OPT[l][v] > OPT[l-1][p] + w(p,v)
                    OPT[l][v] = OPT[l-1][p] + w(p,v)
                   
    retornar OPT[n-1, n]
\end{lstlisting}

La complejidad del primer loop esta acotado por n. La segunda parte se ejecuta m veces por cada predecesor.
O sea es \(O(m*n)\)

La complejidad espacial es m*n porque la matriz ocupa n*m

\underline{RECONSTRUIR LAS ELECCIONES}

Agregar un nodo predecesor y almacenar en la posici√≥n \(i\) cual fue el predecesor del nodo.

\textit{¬øQue pasa si hay un ciclo negativo?}

Si en una iteraci√≥n despues de haber llegado a la longitud maxima, cambia el minimo de al menos un nodo, entonces el grafo \textit{tiene ciclos negativos}.

\newpage
\subsection{Problema de Maximo subarreglo}

Se necesita calcular un subconjunto \textit{contiguo de elementos} \(S\) 
tal que la suma de los valores sea la m√°xima posible. 

El maximo subvector que termina en el elemento \(i\), esta relacionado con el m√°ximo
subvector que termina en el elemento \(i-1\).

\underline{SOLUCI√ìN RECURRENTE}

\begin{align*}
    MAX(1) &= v[1] \\
    MAX(i) &= max\{MAX(i-1), 0\} + v[i]
\end{align*}
    

\underline{SOLUCI√ìN ITERATIVA}

\begin{lstlisting}[language=Python, caption=Soluci√≥n iterativa]

    MaximoGlobal = v[1]
    MaximoLocal = v[1]
    IdxFinMaximo = 1

    Desde i=2 a n
        MaximoLocal = max(MaximoLocal, 0) + v[i]

        si MaximoLocal > MaximoGlobal
            MaximoGlobal = MaximoLocal 
            IdxFinMaximo = i

    Retornar MaximoGlobal

\end{lstlisting}

\newpage
\subsection{Problema de cuadrados minimos}

Dado un conjunto de puntos \(P={(x_1,y_1),(x_2,y_2),...,(x_n,y_n)}\), con \(x_1<x_2<\cdots<x_n\). 
Usamos \(p_i\) para indicar un punto \((x_i, y_i)\). 

Queremos aproximimar mediante segmentos los puntos de \(P\) minimizando el error comentido. 
Los sementos se forman mediante \textit{rectas de aproximaci√≥n} hallando \(a\) y \(b\). 
El calculo del error cometido se obtiene sumando las distancias de los puntos a las rectas. 

Se agrega un parametro de penalizaci√≥n \(C>0\) por cada segmento que se agrega.
\begin{itemize}
    \item A mayor "C" entonces: menos segmentos
    \item A menor "C" entonces: menos error
\end{itemize}

Al analizar una soluci√≥n por \textbf{fuerza bruta} se obtiene una complejidad de \(O(2^{n*n})\).

\underline{SOLUCI√ìN RECURRENTE}

Como no conocemos cual es el ultimo segmento, se elige el √∫ltimo segmento como aquel que \textbf{minimice el error general}.  
O sea que queremos minimizar el error del segmento, mas la constante \(c\) 
mas el error conocido en el \textit{subproblema que contiene los puntos de segmentemos anteriores} 
sea el minimo entre todos los posibles.


\begin{align*}
    OPT(i) &= min_{1 \leq x \leq i} (e_{x,i} + C + OPT(x-1)) \\ 
    OPT(0) &= 0
\end{align*}
    
\noindent
\underline{SOLUCI√ìN ITERATIVA}

\begin{lstlisting}[language=Python, caption=Soluci√≥n iterativa]
    OPT[0] = 0

    Para todo para i,j con i <= j
        Calcular e[i][j]

    Desde j=1 a n
        OPTIMO[j] = +infinito
    
        Desde i=1 a n
            segmento = e[i][j] + C + OPT[i-1]

            si OPTIMO[j] > segmento 
                OPTIMO[j] = segmento

    Retornar OPT[n]

\end{lstlisting}

Analizando la \textbf{complejidad temporal}, el calculo del optimo es \(O(n)\), pero se calculan \(n\) √≥ptimos,
Por lo tanto esta partes es \(O(n^2)\).

Pero como en la primer se itera sobre todos los pares posibles es \(O(n)\). Y como el calculo del error
es \(O(n)\), la primer interaci√≥n termina siendo \(O(n^3)\), y este le gana a \(O(n^2)\).

La complejidad total es \(O(n^3)\).

Para el calculo de la \textbf{complejidad espacial}, los errores se almacenan en \(O(n^2)\), mientras que 
los √≥ptimos en \(O(n)\). Por lo tanto la complejidad espacial total es de \(O(n^2)\).

\newpage
\subsection{Problema del viajante}

Sea un conjunto de \(n\) ciudades "C", un conjunto de rutas de costo de tr√°nsito, existe una ruta 
que une cada par de ciudades.

Queremos obtener el circuito de menor costo que inicie y finalice en una ciudad y
que pase por el resto de las ciudades \textit{una y solo una} vez

Mediante \textbf{fuerza bruta} tenemos que calcular todos los ciclos posibles, y por lo tanto
existen \((n-1)!\) ciclos de longitud \(n-1\). 
Luego por cada ciclo calculamos su costo y nos quedamos con el m√≠nimo. Por lo tanto la complejidad total es \(O(n!)\).

Mediante el \textbf{algoritmo Belman-Held-Karp} lo resuelvo utilizando programaci√≥n dinamica.
Se puede decomponer como el m√≠nimo entre los subproblemas menores con \((n-1)!\) hojas.

\noindent
\underline{SOLUCI√ìN RECURRENTE}

Dado \(S\) un subconjunto de ciudades e \(i\) la ciudad donde estoy parado. \textbf{start} es la ciudad de partida.
La siguiente es la ecuci√≥n de recurrencia:

\begin{align*}
    OPT(i, \{S\}) &= min_{j \in \{S\}} (w(i,j) + OPT(j, \{S-j\})) \\ 
    OPT(i, \emptyset) &= w(i, start)
\end{align*}

\begin{itemize}
    \item El optimo i con el subconjuto s va a ser igual al minimo de los subproblemas que son elegir alguna de las ciudades que estan en s. 
          Sumando el peso de i a j mas el optimo de partir de j hacia el resto de las ciudades (s-j).
    \item En el caso base, ya no quedan ciudades para visitas, entonces solo queda sumar el peso de ir de \(i\) a la ciudad de inicio \textit{Start}.
\end{itemize}
    
\noindent
\underline{SOLUCI√ìN ITERATIVA}
Llamamos a \(C\) al conjunto de todas las ciudades, 1 es la ciudad inicial, y el resto de las ciudades
estan numeradas de 2 a n.


\begin{lstlisting}[language=Python, caption=Soluci√≥n iterativa]

    Desde i=2 a n
        OPT[i][0] = W[i][1]
    
    Desde k=1 a n-2
        Para todo subset S de C-{1} de tamanio k
            Para cada elemento i de S
                OPT[i, S-{i}] = +infinito

                Por cada elemento j de S - {i}
                    r=OPT[j, S-{i,j}] + w[j][i]

                    si (r<OPT[i, S-{i}])
                        OPT[i, S-{i}] = r

    
    CamininoMinimo=+infinito
    Desde j=2 a n
        ciclo = OPT[i, S-{1, i}] + w[1, i]
        Si (CamininoMinimo>ciclo)
            CamininoMinimo = ciclo
    
    Retornar CamininoMinimo

\end{lstlisting}

\begin{itemize}
    \item La primer iteraci√≥n se cargan los casos bases para las \(n\) ciudades.
    \item Despues desarrollamos los subproblemas, primero iteramos las ciudades que quedan por visitar
    \item Luego generamos las variantes de subset y por cada uno calculo el minimo y 
    utilizo los subproblemas de tama√±o menor, ver cual de todos es el minimo.
\end{itemize}

La complejidad total es \(O(n^2 2^n)\)

\newpage
\section{Redes de flujo}

\subsection{Conceptos}

Se trata de problemas de flujos de trafico en redes. 
Por ejemplo, tubos de gas, autopistas, rutas de aviones, redes electricas.

Definiciones:
\begin{itemize}
    \item Los \textbf{ejes} transportan algun tipo de flujo
    \item Los \textbf{v√©rtices} act√∫an como conmutador de tr√°fico entre los diferentes ejes.
    \item Capacidad: cantidada m√°xima que un eje puede transportar.
    \item Fuente: V√©rtices que generan tr√°fico saliente.
    \item Sumidero:V√©rtice que absorbe tr√°fico entrante.
    \item Flujo: Cantidad transportada por eje.
\end{itemize}

Sea \(G=(V,E)\) un grafo dirigido, para todo \(e \in E\) llamamos \(C_e \geq 0\) (valor entero) a su capacidad.
Existe un √∫nico \(s \in V\) llamado fuente (source). O sea no tiene ejes entrantes.
Existe un √∫nico \(t \in V\) llamado sumidero (sink). O sea no tiene ejes salientes.
El resto de los vertices son internos como si fueran conmutadores de fuentes.

\noindent
\textbf{\underline{DEFINICION DE FLUJO}}
El flujo \(s-t\) es una funcion \(f\) que mapea cada \(e\) a un n√∫mero real no negativo,
\(f: E \mapsto R^+\). Un flujo tiene las siguientes caracteristicas:

\begin{itemize}
    \item (Condici√≥n de capacidad) Para cada \(e \in E\), tenemos que \(0 \leq f(e) \leq C_e\).
    \item (Condici√≥n de conversaci√≥n) Para cada nodo \(v\) que no sean \(s\) y \(t\) , tenemos que:
    \[
        \sum_{e into v} f(e)  = \sum_{e out of v} f(e) 
    \]
\end{itemize}

\noindent
\textbf{\underline{PROBLEMA DE FLUJO MAXIMO}}

Definimos \textbf{corte de grafo} como: 

Dividimos los nodos del grafo en dos conjuntos (A y B). Donde la fuente \(s \in A\) y 
el sumidero \(t \in B\). Cualquier flujo \(s-t\) debe cruzar en alg√∫n punto de A a B.
El corte define un limite al caudal m√°ximo del flujo. Pero dos cortes diferentes, 
tienen capacidades de transporte maxima diferentes. Entonces deberia calcular todos
los posibles cortes del grafo tomar el que maximice el flujo segun los limites de la 
red de transporte. Calcular de esta manera se torna inviable.

\begin{quote}
    \textbf{Entonces el problema de flujo maximo, ser√° dada una red de flujo, encontrar el flujo de maximo valor posible.}
\end{quote}


\newpage
\subsection{Algoritmo Ford-Fulkerson}

Calcula el maximo flujo a travez de una red.

\noindent
\underline{\textbf{Grafo residual}}

Dado un red de flujo \(G\) y un flujo \(f\) en \(G\), 
\textbf{definimos el grafo residual \(G_f\) (de \(G\) con respecto a \(f\))} a:

\begin{itemize}
    \item Los mismos v√©rtices de G,
    \item \textbf{Ejes hacia adelante}: Para cada \(e=(u,v) \in E\) en el que \(f(e) < C_e\). 
    Lo incluimos en \(G_f\) con capacidad \(C_e-f(e)\) [\textbf{capacidad residual} de flujo].
    \item \textbf{Ejes hacia atras}: Para casa \(e=(u,v) \in E\) en el que \(f(e) > 0\). 
    Incluimos \(e'=(v,u)\) con capacidad \(f(e)\).
\end{itemize}

\noindent
\underline{\textbf{Cuello de botella}}

Sea \(P\) un \textbf{camino simple} \(s-t\) en \(G_f\), o sea que \(P\) no visita m√°s de una vez el mismo v√©rtice.

Difinimos \textbf{bottleneck(P,f)} a la \underline{capacidad residual m√≠nima} de cualquier eje de P con repecto al flujo \(f\).

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{imagenes/cuello-de-botella.png}
\end{figure}

Lo m√°ximo que se puede transportar es 20, para que no deje cumplir la condici√≥n de capacidad.

\begin{quote}
    \textit{Con el grafo residual, podemos redireccionar el flujo en el camino original para aumentar el flujo total de la red.}
\end{quote}

Tambien nos ayuda a saber cuanto flujo se esta trasportando por ese eje.

Llamamos \(P\) al camino de aumento (\textbf{augmenting path}):

\begin{itemize}
    \item \(P\) es una caminio simple que va de \(s\) a \(t\) en \(G_f\).
    \item \(P\) no visita el mismo nodo mas de una vez.
\end{itemize}
 
Ahora definimos la operaci√≥n \textbf{augment(f,P)} el cual cede un nuevo flujo \(f'\) en e\(G\)

\begin{lstlisting}[language=Python, caption=Operaci√≥n de augment]
augment(f, p)
    Sea b = bottleneck(P, f)
    Para cada eje e=(u, v) perteneciente a P
        Si e=(u,v) eje hacia adelante
            f(e) += b en G
        sino si es eje para atras 
            e' = (v,u)
            f(e') -=b en G   
    Retornar f
\end{lstlisting}


\begin{figure}[h!]
    \includegraphics[width=\linewidth]{imagenes/camino-aumento.png}
\end{figure}

\textit{¬øEs valido el nuevo flujo?}PENDIENTE

Con el grafo residual y el camino de aumento definimos el \textit{pseudoc√≥digo de Ford-Fulkerson}.


\begin{lstlisting}[language=Python, caption=Operaci√≥n de augment]
Max-Flow
    Inicialmente  f(e)=0 para todo 'e' en G

    Mientras haya un camino s-t en Gf

        Sea P un caminio s-t simple en Gf
        f' = augment(f,P)

        Actualizar f para ser f'
        Actualizar Gf para ser Gf'


    Retornar f
\end{lstlisting}

La \textbf{complejidad} es \(O(|E|*C)\) donde \(|E|\) es la cantidad de ejes y C es la suma de todas
las \(C_e\) de los ejes que salen de la fuente.


\textit{¬øEs √≥ptimo?}PENDIENTE

\begin{quote}
    \textbf{El flujo retornado por el algoritmo Ford-Fulkerson es el flujo m√°ximo}
\end{quote}

Ademas podemos mediante BFS en \(G_f\) construir el corte m√≠nimo s-t (A,B) obteniendo A y por diferencia B.

Consideraciones si las capacidades no son enteras:
\begin{itemize}
    \item Si son racionales, multiplicar por minimo comun multiplo
    \item Si son irracionales, \textit{no esta asegurado que el algoritmo termine}.
\end{itemize}

\subsection{Variante: Circulaci√≥n con demanda}

Cada nodo pueder ser productor o consumir de flujo. O un nodo que no es consumidor ni productor de flujo.

\newpage
\subsection{Bipartite Matching Problem}

Llamamos un grafo bipartito a \(G=(V,E)\) un \textit{grafo no dirigido}, puede particionarse en 
como \(V=X \cup Y\), con la propiedad de que cada eje \(e \in E\) se conecta en una punta con
un nodo en \(X\) y la otra punta un nodo en \(Y\). Un \textit{matching M} en \(G\) es un subconjunto
de ejes \(M \subseteq E\) tal que cada nodo aparece en al menos un eje en \(M\).
Se necesita encontrar el set \(M\) de mayor tama√±o posible. O sea la mayor cantidad de parejas.


Resolvemos el matching utilizando el problema de flujo m√°ximo.
Construimos una red de flujo \(G'\) como la siguiente imagen. Pasamos todos los ejes a ejes dirigidos de
\(X\) a \(Y\). Luego agregamos el nodo \(s\) y un eje \((s,x)\) desde \(s\) a cada nodo en \(X\). 
Tambien agregamos el nodo \(t\) y un eje \((y,t)\) desde cada nodo en \(Y\) a \(t\).
Finalmente, le damos una capacidad de \(1\) a cada eje en \(G'\)

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{imagenes/bipartito-redes-flujo.png}
\end{figure}

Resolvemos el problema de red de flujo m√°ximo con \(G'\). Obtenemos el flujo m√°ximo \(s-t\). Entonces
\textit{El valor del flujo total es igual al tama√±o del matiching m√°ximo.}

\textbf{Analisis} Pendiente

\newpage
\subsection{Dise√±o de encuentas}

Considere el problema de una compa√±ia que vende \(k\) productos y que tiene una base de datos con el 
historias de las compras de todos sus clientes. La compa√±ia desea enviar encuestas con preguntas
personalizadas a un grupo particular de \(n\) clientes, para determinar que productos la gente 
prefiere sobre el total.

Lineamientos para la encuesta:
\begin{itemize}
    \item Cada cliente recibira preguntas acerca de cierto subconjunto de productos.
    \item Un cliente solo puede contestar sobre los productos que √©l o ella haya comprado.
    \item Cada cliente sera preguntado sobre un n√∫mero de productos entre \(c_i\) y\(c'_i\) 
    \item Cada producto debe tener entre \(p_j\) y \(p'_j\) preguntas de clientes distintos.
\end{itemize}

El problema de dise√±o de encuentas toma como input un \textit{grafo bipartito} \(G\) cuyos nodos son 
clientes y productos, y hay un eje entre un cliente \(i\) y un producto \(j\) si el cliente compro el producto \(j\).
Mas a√∫n, por cada cliente \(i=1,2,...,n\) tenemos la limitante de \(c_i \leq c'_i\) en el numero de productos en el que un 
cliente puede constestar; por cada producto \(j=1,...,k\), tenemos la limitante \(p_j \leq p'_j\) en el 
n√∫mero de cliente distintos que se pueden consultar por cada producto.

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{imagenes/grafo-encuesta.png}
\end{figure}

El problema se resuelve reduciendo este a un problema de red de flujo en \(G'\) con demanda y un limite inferior. 

Para obtener un grafo \(G'\) de \(G\), necesitamos:
\begin{itemize}
    \item Orientar los ejes de \(G\) desde los clientes a los productos.
    \item Agregar un nodo ficticio \(s\) con los ejes \((s,i)\) por cada cliente \(i=1,...,n\).
    \item Agragar un nodo ficticio \(t\) con los ejes \((j,t)\) por cada producto \(j=1,...,k\).
\end{itemize}

La circulacion en la red, corresponde con la manera en la que se tienen que realizar las preguntas.

Se debe pasar de un problema de circulaci√≥n con \textit{demanda y limite inferior} a un problema
de circulaci√≥n con demanda y luego a un problema de flujo m√°ximo. Finalmente se resuelve con Ford-Fulkerson.

Una vez obtenido el flujo m√°ximo:

\begin{itemize}
    \item El flujo que va de \((t,s)\) corresponde al n√∫mero total de preguntas a realizar.
    \item El flujo en los ejes \((s,i)\) es el n√∫mero de productos que deben contener el cuestionario para cada cliente \(i\).
    \item El flujo en los ejes \((j,t)\) corresponde con √©l numero de clientes que deben ser preguntados para el producto \(j\).
    \item Por ultimo, aquellos ejes \((i,j)\) con flujo 1, corresponden a preguntar al cliente \(i\) sobre el producto \(j\).
\end{itemize}

\newpage
\subsection{Problema de Selecci√≥n de proyectos}

Dado un conjunto \(P\) de proyectos para seleccionar y cada proyecto \(i \in P\) tiene
asociado una ganancia \(p_i\), el cual puede ser \textit{positivo} como \textit{negativo}.
Algunos proyectos son requisitos de otros proyectos, y modelaremos esta relaci√≥n mediante un \textit{grafo
dirigido sin ciclos} \(G=(P,E)\). Los nodos de \(G\) son los proyectos y hay un eje \((i,j)\) para indicar
que un proyecto \(i\) puede ser seleccionado solo si el proyecto \(j\) es tambien seleccionado.
Un proyecto \(i\) pude tener muchos prerequisitos, y puede haber muchos proyectos \(j\) que pueden
ser parte de esos prerequisitos. Un conjunto de proyecto de \(A \subseteq P\) es \textit{viable} si los 
prerequisitos de cada proyecto de \(A\) tambien pertenecen a \(A\):
\begin{quote}
    Por cada \(i \in A\) y cada eje \((i,j) \in E\), tenemos que \(j \in A\)
\end{quote}
Estos prerequisitos vendrian a ser las \textit{restricciones de precedencia}. La ganancia del conjunto de proyectos
se define como:

\[
    profit(A) = \sum_{i\in A} p_i 
\]

El \textit{problema de selecci√≥n de proyectos} seleccionar el conjunto de proyectos viables con la maxima ganancia.


\newpage
\section{Problemas NP}

\subsection{Clasificaci√≥n}

\subsubsection{Clase P}

La clase \(P\) consiste en aquellos problemas que pueden resolverse en tiempo polinomial (eficientemente).

Un algoritmo A resuelve \textbf{eficientemente} un problema \(S\) si para toda instancia \(I\) de \(S\),
encuentra la soluci√≥n en tiempo polinomico, entonces existe una constante \(k / A = O(n^k)\) 
y donde \(n\) es el tama√±o de la entrada del problema. 
Ejemplo, Gale Shapley resuelve el problema de "Stable Marriage Problem" en \(O(n^2)\)

Se conoce como \(P\) al conjunto de problemas de decisi√≥n para los que existe un algoritmo que lo resuelva en
\textit{forma eficiente}.

Un algoritmo B \textbf{certifica eficientemente} un problema de decisi√≥n \(S\)  si para toda instancia \(I\) de \(S\),
dado un certificado \(t\) que contiene evidencia de la soluci√≥n \(s(i)\) es \textit{"Si"}, 
entonces existe una constante \(k / B = O(n^k)\). 

O sea que el algoritmo B va a recibir dos parametros, la instancia \(I\) y el certificado \(T\).  
Responde si o no. Por ejemplo, en el problema de la moneda, seria las cantidades de monedas a dar, 
y certificado seria la soluci√≥n conocida. Para validar, se ejecuta el algoritmo de certificaci√≥n
con el certificado \(T\).


\subsubsection{Clase NP}

Se conoce como \(NP\) al conjunto de problemas de decisi√≥n para los que existe un algoritmo
que lo verifique (certifique) en tiempo polinomial (eficientemente).

¬ø\(P \subseteq NP\)?. Si el problema \(Q \in P\), existe un algoritmo \( A = O(n^k)\) que lo resuelve. Y podemos definir como:

\begin{lstlisting}[language=Python, caption=Algoritmo B]

    B(I, t)
        s = A(I)
        Si s == t
            retornar "si"
        retornar "no"

\end{lstlisting}

Que certifica el problema \(Q\) y lo hace en tiempo polinomial. Entonce se cumple:

\[
    Q \in P \implies Q \in NP
\]

¬ø\(NP \subseteq P\)?. Es un problema sin resolver.


\subsection{Reducciones}

Reducir un problema a otro conocido.

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{imagenes/reduccion.png}
\end{figure}

Una reducci√≥n polinomial corresponde a una reducci√≥n en la que ambas transformaciones se realizan en tiempo polinonimial.

Sean X, Y problemas, diremos \(Y \leq_p X\), se lee Y es polinomialmente reducible (en tiempo) a "X"

Si podemos transformar cualquier instancia de \(Y\) en una instancia de \(X\) en tiempo polinomico (tractable).

Para \textbf{comparar problemas} con reducciones, sean \(X, Y\) problemas, si \(Y \leq_p X\), diremos que 
el problema \(X\) es al menos tan dificil que el problema \(Y\)

Para \textbf{acotar un problema} a la clase \(P\). 
\begin{itemize}
    \item Sean \(X,Y\) problemas si \(X \in P\) y \(Y \leq_p X\) 
    entonces \(Y \in P\), porque \(X\) es igual de complicado que \(Y\). Ejemplo:
    \begin{gather*}
        MAXMATCHING \leq_p MAXFLOW \\
        MAXFLOW \in P \implies MAXMATCHING \in "P"    
    \end{gather*}
    
    \item Sean \(X,Y\) problemas si \(Y \notin P\) y \(Y \leq_p X\) 
    entonces \(X \notin P\), porque \(X\) es igual de complicado que \(Y\).
    
\end{itemize}

Las siguientes son propiedades de reducciones:

\begin{itemize}
    \item \textit{Equivalencia}: Sean \(X,Y\) problemas si \(Y \leq_p X\) y \(X \leq_p Y\) 
    entonces \(X\) e \(Y\) tiene la misma complejidad.
    \item \textit{Transitividad}: Si \(Z \leq_p Y\) y \(Y \leq_p X\) 
    entonces \(Z \leq_p X\)
\end{itemize}


\subsection{Clase NP completo}

\subsubsection{Problema de satisfabilidad booleana - SAT}
Dado un conjunto de variable booleanas que definen una expresi√≥n booleana, determinar si existe una
asignaci√≥n de valores de las variables, tal que el resultado de la expresi√≥n es "TRUE".

Sea una instancia \(I\) del problema \textbf{SAT} \(\in NP\) y un certificado que corresponde a un valor
de asignaci√≥n de cada variable.

Podemos certificar en tiempo polinomial si esa asignaci√≥n de variables producen un resultado "TRUE".

El \textbf{teorema de Cook-Levin} dice, sea \(X \in NP\) entonces \(X \leq_p\) Boolean satisfability problem (SAT). 
O sea, \textbf{que todo problema perteneciente a NP es a lo sumo tan complejo de resolver que SAT}.
 
\textbf{NP-HARD}: Sea un problema \(X\) tal que para todo problema \(Y \in NP\) y \(Y \leq_p X\), entonces \(X \in NP-HARD\).
\textbf{X es al menos igual de dificil que cualquier problema NP}.

\textbf{NP-Complete}: Sea un problema \(X\) tal que para todo problema \(X \in\)NP-HARD y \(Y \in \) NP, entonces \(X \in NP-C\).
\textbf{X es uno de los problemas mas dificiles dentro de NP}.

\underline{Ejemplo de uso}, para cada problema de \(X \in NP\) que analiza Richard Carp, toma un problema 
demostrado como NP-C y lo reduce a \(X\), con esto \(X\) pasa a ser un problema \textbf{NP-C}.

\textbf{Probar que un problema} es \textit{NP-C}. Sea el problema \(X\) de decisi√≥n. Probamos:

\begin{itemize}
    \item Probar que \(X \in NP\), definiendo un certificado eficiente:
    \item Probar que \(X \in NP\)-HARD, dado un problema \(Y \in NP\)-C, 
    reducir polinomialmente \(Y\) a \(X\). Eligiendo el problema \(Y\) correcto para reducir, 
    podemos obtener \(Y \leq_p X\) y agregar a \(X\) en la clasificaci√≥n de los problemas \textit{NP-C}.
\end{itemize}


\subsection{Problema de conjunto independiente}

Sea un grafo \(G=(V,E)\), un valor \(K\), determinar si existe un conjunto independiente de nodos 
de como mucho tama√±o k.

Definimos un conjunto de nodos \(C \subseteq V\) es independiente si no existe \(a,b \in C\) tal que existe eje \((a,b) \in E\) 
y el \textbf{tama√±o del conjunto independiente} corresponde con la cantidad de nodos dentro del conjunto C.

\begin{figure}[h!]
    \includegraphics[width=\linewidth]{imagenes/conjunto-independiente.png}
\end{figure}

Dado un grafo \(G=(V,E)\) con tama√±o \(k\) de conjunto y un certificado \(T\) igual 
al subconjunto de nodos. Si se puede verificar en tiempo polinomial con \(|T| = K\) que:
\[
    \forall a,b \in T, !\exists (a,b) \in E \implies INDEPENDENTSET \in NP    
\]

\subsubsection{3-SAT}
Es una variante de SAT donde cualquier instancia de SAT se puede reducir polinomialmente a 3SAT:

\[
    SAT \leq_p 3SAT \implies 3SAT \in NPComplete
\]

Dado \(X={x_1,...,x_n}\) conjunto de \(n\) variables booleanas = \(\{0,1\}\) y 
\(k\) \textit{clausulas} booleanas \(T_i=(t_{i1} \lor t_{i2} \lor t_{i3} )\) 
con cada \(t_{ij} \in X \cup \overline{X} \cup {1}\). Entonces debemos 
\textbf{determinar si existe asignaci√≥n de variables} tal que \(T_1 \land T_2 \land ... \land T_k = 1\)

\newpage
\subsubsection{Reducci√≥n de 3-SAT a INDEPENDENT-SET}
Por cada \textit{clausula} \(T_i=(t_{i1} \lor t_{i2} \lor t_{i3} )\) \textbf{vamos a generar tres vertices entre si}.
Y por cada \(t_{ij}=x_a,t_{kl}=\overline{x_a} \), crear un eje entre \(t_{ij}\) y \(t_{kl}\).

\begin{figure}[h!]
    \includegraphics[scale=0.4]{imagenes/reduccion-3sat.png}
\end{figure}

\textbf{El grafo resultante }\(G\) corresponde a una instancia del problema \textit{INDEPENDENT-SET} 
con k=numeros de clausulas en la expresi√≥n. Ejemplo, sea la expresi√≥n:

\(E=(x_1 \lor x_2 \lor x_3) \land (\overline{x_1} \lor \overline{x_2} \lor \overline{x_4}) 
    \land (\overline{x_2} \lor \overline{x_3} \lor x_4) 
    \land (\overline{x_1} \lor \overline{x_2} \lor x_3)\)

Reducimos polinomialmente y resuelvo:
\begin{figure}[h!]
    \includegraphics[scale=0.4]{imagenes/ejemplo-reduccion-3sat.png}
\end{figure}

Entonces, luego resuelvo 3SAT con \(x_1 = 1\), \(\overline{x_2} = 1 \implies x_2=0\), 
\(x_4=1\) y elijo \(x_3=0\) porque en este caso es indistinto.

Por lo tanto, como INDEPENDENT-SET \(\in NP\) y \(3SAT \leq_p INDEPENDENTSET\) NP.

Entonces INDEPENDENT-SET \(\in NPComplete\)

\newpage
\subsection{Problema de cobertura de vertices}
Sea un grafo \(G=(V,E)\) diremos que existe un conjunto \(S \subseteq V\) es una cobertura de v√©tices si:
\[
    \forall \;eje\; e \in E=(u,v), u\in S \;\; y/o \;\; v \in S
\]
Donde \(u\) y/√≥ \(v\) pertenecen al conjunto \(S\).

El \textbf{problema de decisi√≥n} sera que dado un grafo \(G=(V,E)\), determinar si existe una conbertura
de v√©rtices (VERTEX-COVER) de tama√±o al menos \(k\). 
\textbf{El problema de optimizaci√≥n busca el subconjunto de menor tama√±o}.


\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/ejemplo-cobertura-v-k3.png}
    \caption{\small \sl Ejemplo de conbertura de vertices de k=3.\label{fig:Stupendous}} 
    \end{center}
\end{figure}

Para ver si VERTEX-COVER pertenece a un \textbf{problema NP}, verificamos de la siguiente manera: 

Sea un grafo \(G=(V,E)\) y un certificado \(T\) como un conjunto de nodos de \(V\) que forman el cubrimiento. 
Verificamos que:
\[
    \forall \;eje\; e \in E=(u,v), \; si \; u\in T \;\; o \;\; v \in T \implies O(V*E)
\]
observamos si uno de estos vertices pertenece al certificado y lo podemos ver en tiempo polinomial de \(O(V*E)\) y si ademas \(|T|=k\), 
entonces el certificado nos da la respuesta con tama√±o k, y por lo tanto \textbf{VERTEX-COVER} \(\in\) \textbf{"NP"}

Para ver si VERTEX-COVER pertenece a un \textbf{problema NP-Completo}, utilizaremos INDEPENDENT-SET.

\newpage
\subsection{Problema de cobertura de conjunto}

Sea un conjunto \(U\) de \(n\) elementos. Una colecci√≥n \(S_1,...,S_m\) de subconjuntos de U. 
Problema de decisi√≥n: ¬øExiste una colecci√≥n de como mucho \(k\) de los subconjuntos cuya uni√≥n es igual a U?

La idea es probar que SET-COVER es NP-COMPLETO. Sea U un conjunto de elementos, 
K tama√±o buscado, los subset \(S_1,...,Sm\) y un \(T\) certificado con los indices de los subconjuntos del conjunto.

Verificamos que \(|T|=k\) para todo elemento en \(U\), si existen en algunos de los subconjuntos de \(T\). 
Por lo tanto se puede hace en tiempo polinomial y se puede afirmar que \textbf{SET-COVER es "NP"}.

Luego elegimos un problema que previamente se haya demostrado que es NP-Completo. Para esto vamos a usar VERTEX-COVER.
Vamos a intentar demostrar que VERTEX-COVER \(\leq_p\) SET-COVER. El algoritmo de reducci√≥n sera:

\newpage
Para la \textbf{reducci√≥n de VERTEX-COVER a SET-COVER}, partimos de \(G=(V,E)\) y \(k\). Queremos que todos los ejes
queden cubiertos y construimos un conjunto de elemtentos U=E. Por cada vertice \(v \in V\), 
creamos un subconjunto \(S_v\) con todos los ejes incidentes a el, y mantenemos en \(k\) la cantidad
de subconjuntos a buscar para cubrir U. Toda esta transformaci√≥n se puede hacer en tiempo polinomial.

Si encontramos el subconjunto, eso nos dira que vertices seleccionar.

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/ejemplo-set-cover.png}
    \caption{\small \sl Ejemplo de reducci√≥n de VERTEX-COVER a SET-COVER.\label{fig:Stupendous}} 
    \end{center}
\end{figure}

Si se resuelve SET-COVER, se obtiene los subconjuntos que corresponden a los nodos resultantes en el 
problema de VERTEX-COVER.

Resumiendo, demostramos que SET-COVER es NP-COMPLETO, porque reducimos VERTEX-COVER a SET-COVER en tiempo
polinomial, y si resolvemos cualquier instancia de set-cover, podemos resolver cualquier instancia
de vertex-cover.

\newpage
\subsection{Problema 3 Dimensional Matching}

Dado 3 conjuntos disjuntos \(X, Y, Z\) de tama√±o \(n\) 
cada uno y un conjunto \(C \subset X \times Y \times Z\) de trip\(X, Y, Z\)las ordenadas. Determinar si existe
un subset de \(n\) triplas ene \(C\) tal que cada elemento de \(X \cup Y \cup Z\) sea contenido
exactamente en una de esas triplas.

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/ejemplo-3DM.png}
    \caption{\small \sl Ejemplo de uso de 3DM.\label{fig:ejm3dm}} 
    \end{center}
\end{figure}

\subsubsection{3DM pertenece a los problemas NP?}

Para verificar que 3DM pertenece a NP, dado 3 conjuntos disjuntos \(X, Y, Z\), \(C=(x,y,z)\) 
conjunto de triplas y un certificado \(T\), de triplas con un subconjunto de C.

Podemos certificar en tiempo polinomial que todo elemento en X, Y y Z, \underline{se encuentra 1 
y solo 1 vez en algun} \(T_i\). Y si \(|T|=n\), entonces:
\[
    3DM \in NP
\] 

\subsubsection{3DM pertenece a los problemas NP-HARD ?}

Ahora queremos probar que 3DM pertenece a los problemas NP-HARD. Probamos que \(3SAT \leq_p 3DM\).

Sea \(I\) instancia de \textit{problema 3SAT} con \(n\) variables \(x_1,...,x_n\) y \(k\) clausulas \(c_1,...,c_k\), 
reducimos en tiempo polinomial la instancia \(I\) a un \textit{problema 3DM}.

\begin{quote}
    \textbf{Gadget:} Formas o plantillas pre-armadas para hacer reducci√≥n de cualquier instancia. 
    Se van a utilizar gadget para las variables y para las clausulas.
\end{quote}

\subsubsection{Reducci√≥n de 3SAT a 3DM}

Por cada variable \(x_i\) creamos un gadget formado por los siguientes conjuntos:
\begin{enumerate}
    \item \(A_i=\{a_{i,1},a_{i,2},...,a_{i,2k}\}\) , seria el nucleo del gadget (2k elementos)
    \item \(B_i=\{b_{i,1},b_{i,2},...,b_{i,2k}\}\) , seria las puntas del gadget (2k elementos)
\end{enumerate}

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[scale=0.3]{imagenes/ejemplo-3dm-gadget-xi.png}
    \caption{\small \sl Ejemplo para 2k elementos. Para la variable xi y k=2 clausulas, se generan 4 elementos por conjunto} 
    \end{center}
\end{figure}

Por cada variable \(x_i\) creamos triplas que van a estar formados por dos elementos del nucleo del gadget
y 1 elemento de la punta del gadget: 

\[
    t_{ij}=\{a_{i,j}, a_{i,j+1}, b_{i,j}\}
\]

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[scale=0.3]{imagenes/ejemplo-3dm-gadget-clausula-xi.png}
    \caption{\small \sl Las triplas se superponen. Cada uno de los elemento del nucleo va a formar parte de dos triplas. Cada elemento 
    de la punta estara unicamente dentro de una tripla. Luego numeramos las triplas segun el valor de \(j\) y lo hacemos 
    en el orden de las agujas del reloj, \textit{llamamos tripla par, si j es par y tripla impar si j es impar}.} 
    \end{center}
\end{figure}

Por cada clausula creamos un set de elementos llamados nucleos:\(C_j=\{p_j,p'_j\}\). Por cada
variable \(i\) en la clausula \(C_j\):
\begin{itemize}
    \item Si contiene la variable \(\overline{x_i}\) \(\rightarrow\) creamos la tripla \(p_j, p'_j, b_{i,2j-1}\)
    \item Si contiene la variable \(x_i\) \(\rightarrow\) creamos la tripla \(p_j, p'_j, b_{i,2j}\)
\end{itemize}

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[scale=0.3]{imagenes/ejemplo-3dm-gadget-ci.png}
    \caption{\small \sl Ejemplo con clausula 1: con la variable  \(\overline{x_i}\)=1 y j=1, la tripla formada sera \(p_1, p'_1, b_{1,1}\).}
\end{center}
\end{figure}

CONTINUACION PENDIENTE.


\newpage
\subsection{Ciclo Hamiltoneano}
Sea un grafo G=(V,E) dirigido definimos un ciclo C en G como hamiltoneano si visita cada v√©rtice
1 y solo 1 vez. Es un recorrido que inicia y finaliza en el mismo vertices.

El problema de decisi√≥n sera HAM-CYCLE, sea G=(V,E) grafo dirigido, ¬øexiste un ciclo hamiltoneano?


\begin{figure}[h!]
    \begin{center} 
    \includegraphics[scale=0.3]{imagenes/ejemplo-ciclo-hamilton.png}
    \caption{\small \sl Ejemplo de un ciclo de hamilton.\label{fig:hamilton-ej}} 
    \end{center}
\end{figure}

Para saber si el HAM-CYCLE pertenece a NP, dado un grafo G=(V,E) 
y un certificado \(T = \{t_0,...,t_{|v|}\}\) lista ordena de vertices.
Puedo verificar en tiempo polinomial los siguientes puntos:

\begin{enumerate}
    \item La cantidad nodos en T es igual a la cantidad de vertices en V. \(|T|=|V|\) y \(t_0=t_|M|\).
    \item Todos los v√©rtices de V estan en T.
    \item Para todo par de vertices \(t_i, t_{i+1} \in T\) existe un eje direccionado \((t_i, t_{i+1}) \in E\) que los une. 
    O sea seguimos el camino ordenado de nodos.
\end{enumerate}

Por lo tanto podemos afirmar que \textbf{HAM-CYCLE}\(\in NP\).

NP C - PENDIENTE
\newpage
\subsection{Problema del caballo}

Se conoce como \textit{problema del caballo}, a encontrar una serie de movimientos del caballo de ajedrez
que partiendo de una posici√≥n del tablero recorra todos los casilleros y regrese a la casilla inicial 
sin pisar dos veces la misma casilla. 

¬øEs posible que un caballo de ajedres desde una posici√≥n determinada recorra todo el tablero sin 
pisar dos veces la misma casilla?

Para tableros nxn en "Solution of the knight‚Äôs Hamiltonian path problem on chessboards" Axel Conrad 
probaron que:

\begin{itemize}
    \item si \(n \geq 5\) se puede hallar un \textit{camino} hamiltoneano.
    \item si \(n \geq 6\) se puede hallar un \textit{ciclo} hamiltoneano.
\end{itemize}

Es un caso particular del ciclo hamiltoneano y que se puede resolver en forma polinomial para ambos casos.

\begin{quote}
En particular no interesa analizar si el problema es un NP-Completo el cual no podemos resolver √≥ existe 
un caso particular como este que si.
\end{quote}

\newpage
\subsection{Problema del viajante de comercio}
Un viajante debe recorrer \(n\) ciudades \(v_1,v_2,...,v_n\) partiendo de \(v_1\) se debe construir
un tour visitando cada ciudad una vez y retornar a la ciudad inicial.

\textbf{Caminos:} Para todo par de ciudades: 
\begin{itemize}
    \item Se especifica una distancia \(d(v_x,v_y)\) entre las ciudades.
    \item No necesariamente hay simetria: \(d(v_x,v_y)\) puede ser diferente a \(d(v_y,v_x)\)
    \item No necesariamente se cumple la desigualdad triangular: \(d(v_i,v_j)+d(v_j,v_k)>d(v_i,v_k)\)
\end{itemize}
Esto es un caso generalizado.

\textbf{Problema de decisi√≥n:} Dado \(n\) ciudades y las distancias entre cada par de ciudades, 
determinar un tour(o ciclo) de distancia total menor a \(k\). \(k\) sera un parametro del problema.

\subsubsection{Problema del viajante es NP?}

Sea \(n\) ciudades, las distancias entre cada par de ciudades, \(T\) certificado = tour de ciudades y \(k\)
distancia como limite. Se debe verificar \(T\) contiene todas las ciudades (solo 1 vez) y termina y comienza en la misma. 
Y por ultimo, la suma de las distancias recorrida es menor a \(k\). Todas estas verificaciones se puede hacer en timpo polinomial
y por lo tanto el problema del viajante es NP.

\subsubsection{Problema del viajante es NP Completo?}

Utilizamos HAM-CYCLE para reducir al problema del viajante. Sea una instancia \(I\) de HAM-CYCLE \(G=(V,E)\).

\begin{enumerate}
    \item Por cada v√©rtice \(v_i \in V\), creamos una ciudad \(v'_i\)
    \item Por cada arista \(e_{i,j} \in E\), definimos la distancia \(d(v'_i, v'_j)=1\)
    \item Aquellas distancias que no estan definidas(Las que en el grafo original no tienen aristas) las 
    creamos con valor 2. 
\end{enumerate}

Tambien definimos el valor K, el cual es la distancia limite que tienen que medir el camino. 
Ponemos como valor \(k=|V|\) (numero de vertices del grafo original)

Solucionamos el viajante con \(k\) definido si existe un camino con longitud \(k\), entonces existe ciclo hamiltoneano.
Si se encontro un ciclo cuya longitud es mayor a \(k\), es porque se tomo un camino con distancia 2, los cuales no existen 
en el grafo original, y entonces no puede formarse un ciclo hamiltoneano en el grafo original.

Si encontramos el ciclo en le viajante, cuya longitud sea igual a \(k\), y como cada ciudad corresponde a un 
vertice del grafo original, se puede tranformar a un ciclo hamiltoneado. Esta transformaci√≥n es polinomial y 
por lo tanto cualquier problema hamiltoneano lo podemos reducir a un problema del viajante. 
Como antes demostramos que el problema del viajante es NP, entonces podemos decir que el problema del viajante
es NP-Completo.

\begin{quote}
    VIAJANTE \(\in NP\) y \(HAM-CYCLE \leq_p VIAJANTE\) \(\implies\) VIAJANTE \(\in NPComplete\)
\end{quote}

\newpage
\subsection{Coloreo de Grafos}


\newpage
\section{Algoritmos Randomizados}

Un algoritmo randomizado es aquel que resuelve un problema P utilizando 
como parametro extra una cadena aleatoria "\(r\)". Las decisiones de ejecuci√≥n
se realizan teniendo en cuenta la lectura de la cedena aleatoria.

\textbf{Clase de complejidad RP}: Se conoce como "RP" o "R" a aquellos problemas de decisi√≥n
para los que existe un programa "M" randomizado que se ejecuta en tiempo polinomial. Y que para 
toda instancia \(I\) del problema:
\begin{itemize}
    \item Si la instancia \(I\) debe tener como resultado "Si", entonces:
     \[
         Probabilidad(M(I,r)="Si")\geq 1/2
     \] 
    \item Si la instancia \(I\) debe tener como resultado "No" (no debe tener falsos positivos), entonces:
    \[
        Probabilidad(M(I,r)="No") = 0
    \] 
    
\end{itemize}

\textbf{Clase de complejidad co-RP}: Se conoce como "RP" o "R" a aquellos problemas de decisi√≥n
para los que existe un programa "M" randomizado que se ejecuta en tiempo polinomial. Y que para 
toda instancia \(I\) del problema:
\begin{itemize}
    \item Si la instancia \(I\) debe tener como resultado "Si" (no debe tener falsos negativos), entonces:
     \[
         Probabilidad(M(I,r)="No") = 0
     \] 
    \item Si la instancia \(I\) debe tener como resultado "No", entonces:
    \[
        Probabilidad(M(I,r)="No") \geq 1/2
    \]
\end{itemize}

\textbf{Clase de complejidad ZPP}: Se conoce como \textit{zero-error probabilistic P} (ZPP) a aquellos
problemas de decisi√≥n que pertenecen a "RP" y "co-RP". Implica que para toda instancia I del problema
podemos ejecutar el algoritmo en RP y co-RP, entonces en tiempo polinomial tendremos 3 respuestas posibles:
"Si", "No" y "No es posible".

La repetici√≥n de un n√∫mero no determinado de ejecuciones nos asegura obtener el resultado correcto.
Este tipo de clase de complejidad corresponde a los algoritmos de \textbf{Las Vegas}, en la intersecci√≥n RP \(\cap\) co-CP.


\textbf{Clase de complejidad BPP}: Se conoce como \textit{bounded-error probabilistic P} (BPP) a aquellos problemas de decisi√≥n
para los que existe un programa "M" randomizado que se ejecuta en tiempo polinomial. Y que para 
toda instancia \(I\) del problema:
\begin{itemize}
    \item Si la instancia \(I\) debe tener como resultado "Si", entonces:
     \[
         Probabilidad(M(I,r)="Si") \geq 2/3
     \] 
    \item Si la instancia \(I\) debe tener como resultado "No", entonces:
    \[
        Probabilidad(M(I,r)="Si") \leq 1/3
    \]
\end{itemize}

No podemos estar seguros. Si el resultado es correcto, podemos afirmarlo con "alta probabilidad".
Este tipo de clase de complejidad corresponde a los algoritmos de \textbf{Monte Carlo}.

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[scale=0.3]{imagenes/relacion-rp-p-zpp-bpp.png}
    \caption{\small \sl Relaci√≥n entre clases.\label{fig:hamilton-ej}} 
    \end{center}
\end{figure}

\newpage
\subsection{Mezcla aleatoria}

Sea un conjunto A de \(n\) elementos que queremos generar un listado de A ordenado aleatoriamente.
Mezclar conjuntos se utilizan en \textit{juegos de azar, reproducci√≥n de musica aleatoria, modelos estadisticos 
simulaciones, pruebas de complejidad algoritmica y otros mas}.

\textbf{Permutaci√≥n por ordenamientos}: 
Para cada \(i\) elemento en A, generaremos un numero \(p_i\) aleatorio como su clave.
Utilizando \(p_i\) para cada elemento \(a_i\) como "clave", ordenaremos "A". Podemos elegir 
cualquier metodo de ordenamiento como caja negra para resolverlo. O sea ordenamos basandonos
en la clave aleatoria que generamos para cada elemento.


\begin{lstlisting}[language=Python, caption=Algoritmo de permutaci√≥n por odenamiento]
Sea A[1..n] conjunto a ordenar
Sea P[1..n] vector numerico // vector de prioridades.

Desde j=1...n
    P[j] = random_value(1...x)

Ordenamos A utilizando P como clave

Retornar A
\end{lstlisting}

Este algoritmo tiene un problema y es que si se generan claves repetidas, en metodos de 
ordenamientos como los estables, no se realizara la permutaci√≥n y de esta forma no se podra 
obtener una permutaci√≥n aleatoria uniforme (en terminos de probabilidad). 

Para disminuir la posibilidad de claves repetidas, tenemos que tomar las siguientes acciones:

\begin{enumerate}
    \item Podemos establecer un valor de X muy alto. \(X >>> n \) (Por ejemplo \(n^5\)).
    \item Se puede agregar un registro de claves utilizadas y volver a seleccionar otra clave 
            si surge una ya utilizada. En el peor de los casos, se puede obtener siempre la misma
            clave y por consiguiente entrar en un loop infinito, si se elige mal el valor de \(x\).
\end{enumerate}

La complejidad temporal es \(O(n log(n))\) por que la generaci√≥n de claves es \(O(n)\) y el ordenamiento
es \(O(n log(n))\) por lo que mandan el ordenamiento. La complejidad espacial es \(O(n)\).

Seg√∫n el an√°lisis de uniformidad cualquier permutaci√≥n tiene probabilidad \(1/n!\).
Por lo tanto este m√©todo genera una \textit{permutaci√≥n aleatoria uniforme}.

\textbf{Algoritmo de mezcla de Fisher-yates}: Tambien se conoce como "barajado de sombrero".
Se introducen todos los n√∫meros en un sombrero, se agita el contenido(se mezclan) y se van sacando
de a uno y se listan el mismo orden en el que se sacan hasta que no queden ninguno.

La descripci√≥n algoritmica es, para cada elemento A[i], generamos un calor \(x\) al azar entre \(i\) y \(n\). 
Luego intercambiamos A[i] con A[x].

\begin{lstlisting}[language=Python, caption=Algoritmo de Fisher-yates]
Sea A[1..n] conjunto a ordenar

Desde i=1...n
    intercambiar A[i] con A[random_value(i...n)]

Retornar A
\end{lstlisting}    

Seg√∫n el an√°lisis de uniformidad cualquier permutaci√≥n tiene probabilidad \(1/n!\).
Por lo tanto este m√©todo genera una \textit{permutaci√≥n aleatoria uniforme}.

La complejidad temporal es O(n) porque tenemos \(n\) interaciones, y dentro de cada interaci√≥n
tenemos un intercambio que es O(1) y un ramdom que tambien es O(1). La complejidad espacial 
es O(1) porque todo el algoritmo se puede hacer sobre el mismo vector.

Ejemplo con \(A=\{a_1,a_2,a_3,a_4\}\):
\begin{figure}[h!]
    \begin{center} 
    \includegraphics[scale=0.3]{imagenes/ejemplo-mezcla-aleatoria.png}
    \caption{\small \sl Ejemplo de mezcla de Fisher-yates} 
    \end{center}
\end{figure}

\subsection{Problema de K conectividad de en un grafo}

Sea \(G=(V,E)\) grafo conexo y no dirigido, deseamos saber ¬øcuantos ejes se pueden remover antes 
que G deje de ser conexo?. Se espera encontrar la minima cantidad de ejes para que se un grafo conexo.

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[scale=0.5]{imagenes/ejemplo-k-conectividad.png}
    \caption{\small \sl Ejemplo de k conectividad} 
    \end{center}
\end{figure}

Analizamos el problema y lo podemos pensar como encontrar el corte global m√≠nimo del grafo si
analizamos toda posible subdivisi√≥n A-B del grafo en 2 conjuntos disjuntos. En cada 
subdivisi√≥n contamos la cantidad de ejes entre conjuntos y tomamos la subdivisi√≥n con menor 
de ejes. Resolverlo por fuerza bruta, tendria una complejidad exponencial.

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[scale=0.5]{imagenes/ejemplo-subdivicion.png}
    \caption{\small \sl Ejemplo de k conectividad} 
    \end{center}
\end{figure}

Para solver el problema, vamos a realizar una reducci√≥n al problema de flujos:

\begin{enumerate}
    \item Por cada eje \(e=(u,v)\) creamos 2 ejes dirigidos (u,v) y (v,u), les asignamos una capacidad de 1.
    \item Por cada combinaci√≥n posible de dos nodos, etiquetamos como s y t respectivamente y resolvermos \textit{"MAX-FLOW MIN-CUT"}.
    \item El menor de los cortes m√≠nimos corresponde al valor de la K-conectividad del eje del grafo.
\end{enumerate}

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[scale=0.5]{imagenes/ejemplo-k-mincut.png}
    \caption{\small \sl Ejemplo de k conectividad} 
    \end{center}
\end{figure}

La complejidad temporal va a ser \(O(n^5)\) ya que por una lado, vamos a repetir el problema de flujo maximo en \(O(|V|^2)\)
y por el otro en el peor de los casos, si usamos ford-fulkenson la complejidad sera \(O(|V|^3)\).

\textbf{Algoritmo de Karger}: Es un algoritmo randomizado que funciona en tiempo polinomial y
\textit{puede retornar un resultado erroneo}. Utiliza un proceso de contracci√≥n 
(\textit{Contraction Algoritms}). El proceso de contracci√≥n es el siguiente:

\begin{enumerate}
    \item Seleccionar: Un eje \(e=(u,v)\) de forma aleatoria y uniforme.
    \item Reemplazar: Los nodos \(u\) y \(v\) por un nuevo nodo \(w\). Todos los ejes \((u,v)\) 
    se eliminan. Los ejes \((u,a)\) y \((v,a)\) con \(a \in E - \{u,v\}\) se reemplaza por \((w,a)\).
    \item Repetir: Hasta que solo queden 2 nodos en el grafo G resultante.
\end{enumerate}

Para encontrar K con alta probalidad de exito hay que ejecutar el algoritmo varias veces
y quedarnos con la mejor K entre todas las iteraciones. Esto da una complejidad total temporal 
de \(O(|V|^4*log |V|)\), funcionando peor y puede fallar con 
cierta probabilidad. La mejora de \textbf{steiner-karger}(1996) aplica la siguiente variante:


\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/ejemplo-contraccion1.png}
    \includegraphics[width=\linewidth]{imagenes/ejemplo-contraccion2.png}
    \caption{\small \sl Ejemplo de contracci√≥n Karger} 
    \end{center}
\end{figure}



\begin{enumerate}
    \item Si \(|V|\) es peque√±o resuelve por fuerza bruta
    \item Sino contrae \(|V|/\sqrt{2}\) nodos y aplica t√©cnica de divisi√≥n y conquista con el resto.
\end{enumerate}

Con esto encuentra con alta probabilidad K, con \underline{complejidad temporal \(O(|V|^2 log^3 |V|)\)}.

\newpage
\subsection{Resoluci√≥n de conflictos en sistemas distribuidos}

Supongamos que tenemos \(n\) procesos \(P_1, P2,...,P_n\), cada uno compite para acceder a un 
recurso compartido (ejemplo: base de datos). Divimos el tiempo en rondas discretas. 
Las bases de datos tienen la propiedad de que esta puede ser accedida por un solo proceso a la vez
en una ronda. Si dos o mas procesos intenta acceder a esto simultaneamente, entonces todos los procesos
seran lockeados en lo que dura la ronda. 

\textbf{Dise√±o de un algoritmo randomizado}: La aleatoriedad provee un protocolo natural para este 
problema, el cual se puede especificar de la siguiente manera. Para un valor de \(p > 0\), que determinaremos
luego, cada proceso intentara acceder a la base de datos en cada ronda con probabilidad \(p\),
independiente de la decisi√≥n que tomen los otros procesos. Entonces:

\begin{enumerate}
    \item Si exactamente un proceso solicita el recurso en una ronda, lo conseguira con exito.
    \item Si dos o mas procesos solicitan el recuros, se lockearan.
    \item Si nadie solicita el recurso, el turno se pierde.
\end{enumerate}

Esta estrategia, se conoce como quiebre de simetria. Si cada vez que un proceso falla,
solicita el proceso inmediatamente en el turno siguiente se provocar√° un atasco, pero 
utilizando la aleatoriedad se puede corregir la contensi√≥n.


ANALISIS PENDIENTE!!


En concluci√≥n, con probabilidad de \(1-n^{-1}\) todos los procesos tendran exito en 
acceder al recurso al menos 1 vez en no mas de \(t=2*\ceil{en}*lnO(n)\) rondas.


\newpage
\subsection{Quick Sort Randomizado}

Sea un set \(S=\{a_1, a_2,...,a_n\}\), la mediana es el n√∫mero que queda en la posici√≥n del medio si
se presentan ordenados. Formalmente, el mediano de S es igual K-esimo elemento mas grande en S, donde:

\begin{itemize}
    \item Si \(n\) es impar, \(K=n/2\).
    \item Si \(n\) es par, \(K=(n+1)/2\).
\end{itemize}
La complejidad de Resoluci√≥n hasta aqui es de \(O(n log n)\) debido al ordenamiento.


\begin{lstlisting}[language=Python, caption=Algoritmo para calcular la mediana utilizando divisi√≥n y conquista]
select(S,k)
    Sl={}  Sr={}
    p = calcular_pivot(k)
    Desde j=1 hasta k
        Si sj < p
            Sl += {sj}
        Si sj > p
            Sr += {sj}
    
    Si size(sl) = k-1
        return p
    Sino si size(sl) > k - 1
        select (sl, k)
    sino 
        select (sr, k-1 - size(sl))

\end{lstlisting}    
    
Analizando la funcion calcular pivot, calculamos un pivot "centrado" que al menos
\(\epsilon*n\) elementos menores y mayores que √©l(\(\epsilon>0\)). 
Proponemos seleccionar un \(a_i \in S\) como \textbf{pivot uniforme al azar},
considerando centrales a los elementos que al menos dejen 1/4 de los elementos 
del lado izquierdo o derecho. La mitad de los elementos son centrales (\(\epsilon = 1/4\)).
La probabilidad de seleccionar un pivot central es de 1/2.

Al dividir en S+ y S- verificamos que la divisi√≥n cumpla el requisito, y sino cumple,
volvemos a seleccionar al azar otro pivot. Probabilisticamente tendria que repetir
a lo sumo 2 veces la elecci√≥n. \textbf{Este proceso es O(n)}.

\textbf{QuickSort} es un algoritmo de ordenamiento que utiliza divisi√≥n y conquista.
Divide en cada paso en dos subproblemas utilizando un valor pivot.
Por un lado se procesan los valores menores al pivot y por el otro los mayores.

\begin{lstlisting}[language=Python, caption=Algoritmo QuickSort]
QuickSort(S)
    Si |S| <= 3
        Ordenar S
        Retornar S
    Sino
        p = seleccionar_pivot(S)
        Por cada elemento de S
            Ponerlo en S- si es menor a p
            Ponerlo en S+ si es mayor a p

        S- = QuickSort(S-)
        S+ = QuickSort(S+)
    
    Retornar S-, p, S+
\end{lstlisting} 

Si el pivot es el valor medio, la complejidad es O(nlog n). Pero si el pivot es malo ser√° \(O(n^2)\).

\textbf{QuickSort Ramdomizado}: Modificamos el quicksort intentando \textbf{elegir un pivot aleatoriamente}.
Al dividir en S- y S+ verificamos que se cumpla el requisito:

\begin{enumerate}
    \item Queremos que el pivot sea central, ni en 1/4 inicial ni en el final.
    \item Si no cumple, volvemos a seleccionar al azar otro pivot.
\end{enumerate}
Probabilisticamente tendria que repetir a los sumo 2 veces la elecci√≥n del pivot.

\begin{lstlisting}[language=Python, caption=Algoritmo QuickSort ramdomizado]
QuickSort(S)
    Si |S| <= 3
        Ordenar S
        Retornar S
    Sino
        Repetir 
        p = seleccionar_pivot(S)
        Por cada elemento de S
            Ponerlo en S- si es menor a p
            Ponerlo en S+ si es mayor a p
        Hasta que |S-| >= 1/4*|S| y |S+| >= 1/4*|S|  
        S- = QuickSort(S-)
        S+ = QuickSort(S+)
    
    Retornar S-, p, S+
\end{lstlisting} 
    
\textbf{El proceso total es O(n*log(n))}.






\newpage
\section{Algoritmos de aproximaci√≥n}

\subsection{Problema del balanceo de carga}

Dado un conjunto de maquinas \(M_1,M_2,..,M_m\), un conjunto de \(n\) tareas donde cada tarea \(j\)
requiere \(T_j\) de tiempo de procesamiento. El objetivo es asignar las tareas a las maquinas
de tal forma que la carga quede balanceada (El tiempo asignado a cada maquina sea lo mas parejo posible).

\textit{¬øComo medimos el balanceo de carga?} Si llamamos \(A(i)\) al conjunto de tareas asignadas a la 
maquina \(i\), podemos calcular la carga de la maquina \(i\) como:
\[
    T_i=\sum_{ j\in A(i)}t_j
\]
Lo que buscamos es minimizar el makespan; esto es simplemente la maxima carga 
sobre cualquier maquina, \(T = max_i t_i\). Podemos medir el balanceo por diferente indicadores:

\textbf{Makespan: max(Ti) para todas las maquinas}

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[scale=0.4]{imagenes/grafico-makespan.png}
    \caption{\small \sl Ejemplo de makespan} 
    \end{center}
\end{figure}

Un m√©todo para seleccionar la asignaci√≥n y la naturaleza de los trabajos determinar√°
la programaci√≥n final de las tareas. El problema para la asignaci√≥n de tareas con minimo makespan 
es NP-HARD.

Vamos a utilizar un \textbf{m√©todo greedy} para realizar la aproximaci√≥n. Para cada tarea i, asignar a la maquina j
con menor carga en el momento.

\begin{lstlisting}[language=Python, caption=Algoritmo de aproximaci√≥n greedy]
Comenzar sin trabajos asignados
Definir Ti=0 y A(i) != 0 para todas las maquinas Mi
Desde j=1 a n
   Sea Mi la maquina con menor Tk (k=1 a m)
   Asignar la tarea j a maquina Mi
   Establecer A(i) <- A(i) union {j}
   Establecer Ti <- Ti + Tj

\end{lstlisting}    

\textbf{Analisis}: Podemos acotar inferiormente el tiempo optimo para el makespan de dos maneras:

\begin{itemize}
    \item \(T* \geq \frac{1}{m}\sum_{j}t_j\): El optimo es mayor o igual al tiempo promedio total.
    \item \(T* \geq max_j t_j\): El optimo es mayor o igual al tiempo del trabajo mas largo.
\end{itemize}

\textbf{El algoritmo asigna los trabajos a las maquinas con un makespan T \(\leq\) 2T*}. Demostraci√≥n pendiente.

En el peor de los casos, si la ultima tarea coincide con aquella de longitud mas grande, quedara
peor balanceado.

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/ejemplo-aproximaci√≥n-balanceo-greedy.png}
    \caption{\small \sl Ejemplo de balanceo con greddy} 
    \end{center}
\end{figure}

\textbf{Algoritmo mejorado}: Se agrega un preprocesamiento para ordenar las tareas segun su duraci√≥n 
en forma decreciente.

\begin{lstlisting}[language=Python, caption=Algoritmo de aproximaci√≥n greedy mejorado]
Comenzar sin trabajos asignados
Ordenar las tarea de mayor a menor duracion
Definir Ti=0 y A(i) != 0 para todas las maquinas Mi
Desde j=1 a n
    Sea Mi la maquina con menor Tk (k=1 a m)
    Asignar la tarea j a maquina Mi
    Establecer A(i) <- A(i) union {j}
    Establecer Ti <- Ti + Tj

\end{lstlisting}    

\textbf{El algoritmo asigna los trabajos a las maquinas con un makespan T \(\leq\) 3/2T*}. Demostraci√≥n pendiente.



\newpage
\subsection{Problema del selecci√≥n de centros}

Tenemos un conjunto de \(S\) de \(n\) sitios. Queremos seleccionar \(k\) centros para construir 
diferentes shopping malls. Esperamos que cada persona de las \(n\) ciudades pueda ir a comprar a 
uno de los shopping, y queremos seleccionar los sitios de los \(k\) shopping centrales.

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/problema-aproximacion-centros.png}
    \caption{\small \sl Ejemplo con k=3 centros} 
    \end{center}
\end{figure}

\begin{lstlisting}[language=Python, caption=Algoritmo de aproximaci√≥n greedy]
    
    Asumimos k < |S| (sino definimos C = S)
    Seleccionar cualquier sitio 's' y convertirilo en un centro C = {s} 
    Mientras |C| < k
        Seleccionar sitio 's' pertenece a S que maximice la distancia dist(s,C)
        C = C U {s}
    Retornar C como los sitios seleccionados
    
\end{lstlisting}    

\begin{quote}
    Algoritmo de aproximaci√≥n greedy que retorna un conjunto C de k puntos tales que r(C) \( \leq \) 2r(C*) donde C* es un conjunto optimo de k puntos.
\end{quote}

Corresponde a una \textbf{2-aproximaci√≥n} del problema de centros.

\newpage
\subsection{Problema del cobertura de conjuntos}
Es un problema ya planeado donde vimos que es NP-Completo, pero al tener grandes aplicaciones podemos
aproximarlo para resolverlo en tiempo polinomial.
Sea un conjunto \(X\) de \(n\) elementos y una lista de F={\(S_1,...,S_m\)} de subconjuntos de elementos de \(X\).

Un \(Set Cover\) es un subconjunto de F cuya uni√≥n es \(X\). El \underline{objetivo} es encontrar el set cover \(S\) con menor cantidad de subset.

Tratando de construir un buen algoritmo construiremos un algoritmo greedy donde iremos seleccionando
un subset de F paso a paso para el cover set. Intentaremos cubrir la mayor cantidad de elementos a√∫n
no seleccionados.

\begin{lstlisting}[language=Python, caption=Algoritmo de aproximaci√≥n greedy]
    
    Empezamos R = X y S = Vacio (Sin conjuntos seleccionados)
    Mientras R != 0
        Seleccionar el conjunto Si con mayor puntos cubiertos en R
        Agregamos Si a S
        Quitamos elementos de Si de R

\end{lstlisting}   

\newpage
\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/ejemplo-problema-aprox-coverset1.png}
    \includegraphics[scale=0.3]{imagenes/ejemplo-problema-aprox-coverset2.png}
    \caption{\small \sl Ejemplo ejecuci√≥n de coverset utilizando Greedy. Se puede observar que el algoritmos nos dio una soluci√≥n que no es la √≥ptima.} 
    \end{center}
\end{figure}

El algoritmo es un \textbf{(1+log n)-algoritmo de aproximaci√≥n}.





\newpage
\subsection{Problema del cobertura de vertices}

Sea un grafo \(G=(V,E)\) no dirigido, donde cada v√©rtice \(i\) tiene un peso \(w_i \geq 0\).
Queremos encontrar un subconjunto \(S \subset V\) donde cada arista de E del grafo
pertenezca a alg√∫n v√©rtice de S.
Minimizando el costo de los v√©rtices seleccionados.
Esta caso es mas general que el problema que ya se vio con pesos en los v√©rtices igual a uno. 

\textbf{Costo pagado}: Existen diferentes sub conjuntos S de V que conforman un vertex cover.
Llamaramos \(w(S)\) como el costo del vertex cover formado por  \(S \subset V\).

La soluci√≥n optima S* es aquella para la que \(w(S*) \leq w(S)\) para todo S.

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/problema-aprox-vertexcover.png}
    \caption{\small \sl Se pueden elegir varios subconjuntos de v√©rtices, pero se busca el de menor costo.} 
    \end{center}
\end{figure}

Mediante el m√©todo de Pricing, podemos pensar cada peso de los \textit{v√©rtices} como un "costo".
Cada \textit{eje} es un "agente" dispuesto a pagar algo al v√©rtice que lo cubre. Entonces se puede ver 
que los agentes deberian pagar un costo para ser cubiertos por lo menos por uno nodo.

Diremos que un vertice esta \textit{pagado} si la suma de lo pagado por sus ejes es igual al costo de sus v√©rtices.

Diremos que un precio \(p_e\) que tiene que pagar un eje \(e\) al vertice \(i \) es justo si no paga 
mas que el costo \(w_i\) del vertice.


\begin{lstlisting}[language=Python, caption=Algoritmo de aproximaci√≥n greedy. La integridad se respeta si se paga el precio justo.]
    
    Definir pe = 0 para todo e pertenece a E

    Mientras exista un eje e=(i,j) tal que i o j no este "Pagado"
        Seleccionar el eje e
        Incrementar pe si violar la integridad
    
    Sea S el conjunto de todos los nodos pagados
    Retonar S

\end{lstlisting}   

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/ejemplo-aprox-vertexcover.png}
    \caption{\small \sl Inicialmente cada eje no paga nada y no esta cubierto, no hay nodo pagado. 
    selecciono algun eje, por ejemplo el e=(a,b). 
    El eje paga el minimo que es 3. Se marca el nodo b como "pagado" y se cubre el eje (a,b) y (b,c).
    Luego selecciono e=(a,d) y se cubre los ejes (a,d) y (a,c) y se marca como pagado el nodo a.
    Por √∫ltimo, selecciono el eje e=(c,d), pagando el minimo que es 2, se cubre el eje (c,d) y se marca como pagado el nodo c.
    El algoritmo termina diciendo que los vertices cubiertos son a,b,d pagando W(s)=3+4+3=10} 
    \end{center}
\end{figure}

\begin{quote}
    El costo del conjunto S retornado por el algoritmo es como mucho el doble de alg√∫n vertex cover posible.
    El algoritmo es un \textbf{2-algoritmo} de aproximaci√≥n
\end{quote}

\[
    w(S) \leq 2w(S*)
\]


\newpage
\subsection{Problema de la mochila}

Supongamos que tenemos \(n\) elementos que queremos guardar en una mochila. Cada elemento \(i=1,..,n\)
tiene dos parametros: un peso \(w_i\) y un valor \(v_i\). Siendo \(W\) la capacidad de la mochila, el
objetivo global del problema es encontrar un subconjunto de \(S\) con los elementos que maximicen el 
valor sujeto a la restricci√≥n del peso total que no debe superar \(W\).



Nuestro problema tomara como entrada los pesos, los valores definidos por el problema y tambien
tomaremos un parametro extra \(\epsilon\), para obtener la precision deseada.

Llamamos \(OPT(i,V)\) al subproblema de determinar el menor peso que se puede obtener con los primeros
\(i\) items cuyo valor iguale o supere el valor de al menos \(V\) en la mochila.

\begin{lstlisting}[language=Python, caption=Algoritmo de aproximaci√≥n con programaci√≥n dinamica usando interativo]
    
    Desde i=0 a n
        OPT[i][0]=0
    
    Desde v=1 a Vmax
        OPT[0][v]=+infinito

    Desde i=1 a n   // Elementos
        Desde v=1 a Vmax // valores 
    
            enOptimo = w[i] + OPT[i-1, v-v[i]]
            noEnOptimo = OPT[i-1, v]

            si enOptimo < noEnOptimo
                OPT[i][v] = enOptimo
            sino
                OPT[i][v] = noEnOptmimo
    
    Desde v=Vmax a 0
        si OPT[n,v] <= w
            retornar OPT[n][v]


\end{lstlisting}   

La complejidad temporal es \(O(nV_{max})\) y la espacial es \(O(nV_{max})\). Para recobrar los elementos seleccionados
debemos almacenar para cada caso si se selecciono o no que √©l elemento este en el √≥ptimo. Iterar desde el √≥ptimo hacia
atr√°s reconstruyendo.

Si llamamos v*=max {\(v_i\)} con \(0 < i \leq n\) podemos acotar:

\[
    V_max = \sum_{j=1}^{n}v_j \leq nv*
\]

Por lo tanto la complejidad de la programaci√≥n din√°mica sera \(O(n^2, v*)\). Si \(n\) es peque√±o
el algoritmos se resuelve en tiempo polinomia. Sino, se resolvera en tiempo pseudo polinomial.

Para realizar la aproximaci√≥n, utilizaremos un parametro \(b\) de rendondeo, 
donde para cada elemento i calculamos:

\[
     \tilde{v_i} = \ceil{v_i/b}b
\]

De esta forma queda acotado \(v_i \leq \tilde{v_i} \leq v_i + b\) y ademas es multiplo de b.
Podemos resolver mediante programaci√≥n dinamica \(v'_i = \ceil{v_i/b}\). De esta forma,
nos quedara un Vmax mas peque√±o, una cota v* mas peque√±o, \textbf{la programaci√≥n dinamica sera 
mas manejable y se ejecutara como si fuese polinomial.}

Para elegir \(b\) utilizaremos:
\begin{itemize}
    \item \(\epsilon\) para generar \(b\)
    \item con \(0 < \epsilon \leq 1\)
    \item Y por comodidad \(\frac{1}{\epsilon}=\epsilon^{-1}\) es un \textit{n√∫mero entero}.
\end{itemize}
Un valor conveniente para \(b=\epsilon v* / 2n\).


\begin{lstlisting}[language=Python, caption=Knapsack-Approx(e:epsilon)]
Knapsack-Approx(e:epsilon)
    Obtenemos el precio maximo vmax
    b = (e/2n) * vmax / 2n
    Para cada elemento i
        Calcular v'i con b

    Resolvemos con programacion dinamica con los valores v'i

    Retornar el conjunto de elementos encontrados.

\end{lstlisting}   

En todo el proceso la \textbf{complejidad temporal global} sera \(O(n^3\epsilon^{-1})\) para un valor
fijo de \(e\) el algoritmo se ejecuta en tiempo polinomial.

Para cualquier \( \epsilon > 0 \), la soluci√≥n aproximada encuentra una soluci√≥n factible cuyo
valor esta dentro de un factor \(1+\epsilon\) de la soluci√≥n √≥ptima.


\newpage
\section{Teor√≠a de la computabilidad}
La teoria de la computabilidad comienza con una pregunta. ¬øQue es una computadora?. Se utiliza una
computadora ideal llamado modelo computacional.

\subsection{Automata finito}

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/ejemplo-maquina-estado.png}
    \caption{\small \sl Ejemplo de tabla de funci√≥n de transici√≥n y diagrama de estados} 
    \end{center}
\end{figure}
\textbf{Definici√≥n formal de automata finito}: Un aut√≥mata finito "M" es una 5-tupla \(\textstyle (Q,  \sum, \delta , q_0, F)\) donde:
\begin{enumerate}
    \item \(Q\) Conjunto finito llamado "estados". (Ejemplo: \(q_0,q_1,q_3\))
    \item \(\textstyle \sum\) Conjunto finito llamado "alfabeto" (ejemplo: 0, 1)
    \item \(\delta: Q \times \textstyle \sum \rightarrow Q\) es una funci√≥n de transici√≥n.
    \item \(q_0 \in Q\) estado inicial (ejemplo \(q_0\)).
    \item \(F \subset Q\) conjunto de estados de aceptaci√≥n. (ejemplo \(q_3\))
\end{enumerate}

El aut√≥mata recibe un string de entrada (escrito en el alfabeto \(\textstyle \sum\)), procesa el string
partiendo del estado inicial utilizando la funci√≥n de transici√≥n y produce una salida:
\begin{itemize}
    \item "Aceptaci√≥n": si al terminar de procesar el string el estado final corresponde a uno de aceptaci√≥n.
    \item "Rechazo" si no es de aceptaci√≥n.
\end{itemize}


\textbf{Definici√≥n formal de computo}: Sea \(M=\textstyle (Q,  \sum, \delta , q_0, F)\) un aut√≥mata finito y 
dado \(w=w_1, w_2, \dots, w_n\) una cadena donde cada \(w_i\) es parte del alfabeto \(\textstyle \sum\), 
entonces \(M\) acepta \(w\) si existe una secuencia de estados \(r_0,r_0,\dots,r_n\) en \(Q\) con las condiciones:

\begin{enumerate}
    \item \(r_0=q_0\)
    \item \(\delta(r_1, w_{i+1})=r_{i+1}\), para cada \(i=0,\dots,n-1\) y
    \item \(r_n \in F\)
\end{enumerate}

La \textit{condici√≥n 1} dice que la maquina de estado comienza en el estado de comienzo. La \textit{condici√≥n 2} dice que la maquina de estado para de un estado a otro deacuerdo a la funci√≥n de transici√≥n.
La \textit{condici√≥n 3} dice que la maquina acepta su entrada si este termina en un estado aceptado. 
Decimos que \textit{M} reconoce el lenguaje \textit{A} si \(A=\{w | M\) acepta a \(w \}\).

\newpage
\subsection{Automata finito no determinista (AFND)}

En una maquina no deterministica puede haber varias opciones para el siguiente paso en cualquier momento.
Al computar una cadena, se van generando en paralelo diferentes ramificaciones de ejecuci√≥n.

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/ejemplo_AFND.png}
    \caption{\small \sl Ejemplo de automata finito no deterministico} 
    \end{center}
\end{figure}

Al finalizar el procesamiento de una cadena, si al menos una rama termina en estado "Aceptaci√≥n", retorna "Aceptaci√≥n".
De lo contrario retorna "Rechazo".

A medida que se procesan las ramas pueden abandonar ramas que llegan a estados siguiente \(\emptyset\).

\begin{quote}
    \textbf{Diremos que dos maquinas son equivalentes si reconcen el mismo lenguaje.}
\end{quote}

\newpage
\subsection{Lenguajes regulares}

Un lenguaje es regular si existe alg√∫n aut√≥mata finito que lo reconozca.

Existen algunas \textit{operaciones} que se pueden aplicar a los lenguajes regulares llamados operaciones
regulares llamados \textit{operaciones regulares} cuyo resultado es tambien un lenguaje regular.
Podemos utilizar los operadores regulares para construir expresiones que describan lenguajes, los cuales
llamaremos \textit{\textbf{expresiones regulares}}. Ejemplo:

\[
    (0 \cup 1)0*
\]

El valor de esta expresi√≥n regular es un lenguaje que consiste en todas las posibles cadenas que
empiezan con 0 √≥ 1, seguido de cualquier cantidad de 0s.

\textbf{Operadores regulares}:

Sean A, B dos lenguajes regulares:

\begin{itemize}
    \item Union: \(A \cup B\)
    \item Concatenaci√≥n: \(A \cup B\)
    \item Estrella \(A*\)
\end{itemize}

\textbf{Definici√≥n de expresi√≥n regular}:
Se dice que \(R\) es una expresi√≥n regular si \(R\) es:
\begin{enumerate}
    \item \(a\) para algun \(a\) en el alfabeto de \(\textstyle \sum\).
    \item \(\epsilon\)
    \item \(\emptyset\)
    \item \(R_1 \cup R_2\), donde R1 y R2 son expresiones regulares.
    \item \(R_1 \circ R_2\), donde R1 y R2 son expresiones regulares.
    \item \(R_1*\), donde R1 es una expresi√≥n regular.
\end{enumerate}

Ejemplo para convertir una expresi√≥n regular \((a \cup b)*aba\) a una AFND. Pasos:

\begin{figure}[h!]
    \begin{center} 
    \includegraphics[width=\linewidth]{imagenes/ejemplo-expresionregular-AFND.png}
    \caption{\small \sl Ejemplo de expresion regular a AFND} 
    \end{center}
\end{figure}



\newpage
\subsection{Maquina de Turing}

Es similar a un automata finito pero con memoria ilimitada y sin restricciones.
El modelo de una maquina de Turing, utiliza un \textit{cinta infinita} con memoria ilimitada. 
Tiene un cabezal de cinta que puede leer y escribir simbolos sobre la cinta.
Inicialmente la cinta contiene una cadena de entrada y el resto esta en blanco.
La maquina continua procesando hasta que decide producir una salida.
Las salida \textit{aceptado} y \textit{rechazado} se obtienen ingresando los correspondientes 
estados de aceptaci√≥n y rechazo.


Diferencias entre un automata finito y una maquina de Turing:

\begin{enumerate}
    \item Puede grabar o leer en la cinta en cada secuencia.
    \item La lectura y escritura puede moverse de izquierda a derecha.
    \item La cinta es infinita.
    \item Los estados especiales para rechazar y aceptar toman efecto inmediatamente. 
\end{enumerate}


Configuaci√≥n

Sucesi√≥n de configuraciones

Computo

Lenguaje Turing Reconocible

Loop en una maquina de Turing



\subsection{Variantes de M√°quinas de turing}

\begin{enumerate}
    \item Con posibilidad de no avanzar ademas de retroceder o avanzar el cabezal.
    \item Con multiples cintas.
    \item No deterministica.
    \item Con impresora donde solo grabo simbolos.
\end{enumerate}

Todas las variantes tienen el mismo poder de computo. Pueden reconocer los mismos lenguajes.

Equivalencia entra una Turing Machine (TM) y una Turing Machine Multicinta(TMM).

\textbf{Turing Machine No Deterministica (NDTM)}: Permite en un punto del computo transicionar en simultaneo a varias posibilidades.
En un arbol de ramificaciones, alguna rama se puede quedar loopeando en infinito. 
El recorrido del arbol debe realizarse mediantes BFS para evitar el loopeo.

FALTA EJEMPLO.

En el ejemplo, la maquina de turing multicinta y la no deterministica tienen el mismo poder de computo.
O sea, que puede reconocer exactamento los mismos lenguajes, y pueden resolver los mismos problemas.


\newpage
\subsection{Tesis Church-Turing}

Entscheidungs Problem: Es un problema de decisi√≥n para encontrar un algoritmo general que decidiese si una f√≥rmula del calculo 
de primer orden es un teorema.

Turing propone su maquina automatica como herramienta de c√°lculo. Alonzo Church desarrolla su c√°lculo lambda para el mismo motivo.

Con la Tesis Church-Turing, se dio el marco para definir que es un algoritmo. Pero al ser una tesis no esta probado.

El \textbf{10mo} problema planteado por David Hilbert, si lo restringimos a 1 variable, es TURING DECIDIBLE.
Pero volviendo al problema original de decidir si una ecuaci√≥n polinomica diofantica (2 o mas variables) tiene raiz entera,
es TURING RECONOCIBLE, pero no es TURING DECIDIBLE. 

\newpage
\subsection{Lenguajes Turing no decidibles}

\textbf{Maquina de Turing universal}: Permite simular cualquier otra maquina de Turing con un input arbitrario.
El input de esta maquina universal, es la maquina a simular y su input.

Existen lenguajes no decidibles:
\begin{itemize}
    \item Halting Problem
    \item Post Correspondence problem
    \item Wang tiles
    \item Conway's Game of Life
    \item 10mo problema de Hilbert
    \item Otros
\end{itemize}

\newpage
\subsection{Lenguajes Turing no reconocibles}

Pueden existir \textit{infinitos leguajes a reconocer} e \textit{infinitas maquinas de Turing} que se pueden generar.

¬øPueden existir lenguajes no reconocibles? Primero vamos a analizar el \textit{tama√±o de los infinitos}(Georg Cantos).

\textbf{Correspondencia entre conjuntos infinitos}: Dos conjuntos infinitos tienen el mismo tama√±o 
si pueden establecer entre ellos una \textit{correspondencia biyectiva}.

\textbf{Conjuntos contables}: Un conjunto contable A es contable si es finito o si su tama√±o es igual
al conjunto de los n√∫meros naturales. Ejemplo: pares, impares, primos, compuestos. Los n√∫meros enteros
con contables si podemos realizar una correspondencia utilizando algun pivoteo. En el caso de 
n√∫meros racionales, utilizando un recorrido tipo espiral, podemos listar los n√∫meros y realizar
la correspondencia con los n√∫meros naturales. Por lo tanto, los numeros racionales son contables.
Pero el conjunto de los n√∫meros reales no son contables, porque no se puede armar una correspondencia.
Al igual que los n√∫meros binarios no son contables.

El conjunto de las Maquinas de Turing es contable ya que puede realizarse una correspondencia con los
n√∫meros naturales. El conjunto de todos los lenguajes no es contable. Y como un lenguaje es reconocible
si una maquina puede reconocerlo. Entonces: 

\begin{quote}
    \textbf{Existen lenguajes no reconocibles por una maquina de Turing}
\end{quote}

\newpage
\subsection{Complejidad algor√≠tmica con m√°quinas de Turing}

\textbf{Clase complejidad temporal}: Sea \(t:N \rightarrow R+\) una funci√≥n, definimos una clase
de complejidad temporal TIME(T(n)) a la colecci√≥n de todos los lenguajes que son decidibles por una
maquina de \(O(t(n))\)-tiempo Maquina de Turing.

\textbf{Clase complejidad temporal P}: P corresponde a la clase de lenguajes que son decibles en
tiempo polin√≥mico utilizando una m√°quina de Turing \textit{deterministica} con cinta √∫nica.

\[
    P=\cup_k TIME(n^k)
\]

\textbf{Clase complejidad temporal NP}: P corresponde a la clase de lenguajes que son decibles en
tiempo polin√≥mico utilizando una m√°quina de Turing \textit{no deterministica} con cinta √∫nica.

Definimos NTIME(t(n))={L|L es un lenguaje decido por un O(T(n))-tiempo MT no determ√≠nisca}

\[
    P=\cup_k NTIME(n^k)
\]

NP: nodeterministic polynomial time

\textbf{Clase complejidad temporal NP-Completo}: Un lenguaje B es NP-completo si satisface 2 condiciones:

\begin{enumerate}
    \item B pertenece a NP, y 
    \item Todo A que pertenece a NP se puede reducir en tiempo polinomial a B.
\end{enumerate}


\newpage
\subsection{Teorema de Levin Cook}

Este teorema permite identificar al problema SAT como el primer lenguaje NP-Completo.

\end{document}




 